2025-11-15 02:02:28,941:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:02:28,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:02:28,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:02:28,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:08:53,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:08:53,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:08:53,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:08:53,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:09:13,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:09:13,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:09:13,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:09:13,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:11:00,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:11:00,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:11:00,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-15 02:11:00,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:30:34,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:30:34,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:30:34,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:30:34,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:30:36,293:INFO:PyCaret ClassificationExperiment
2025-11-16 05:30:36,293:INFO:Logging name: clf-default-name
2025-11-16 05:30:36,293:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 05:30:36,293:INFO:version 3.3.2
2025-11-16 05:30:36,293:INFO:Initializing setup()
2025-11-16 05:30:36,293:INFO:self.USI: 2854
2025-11-16 05:30:36,293:INFO:self._variable_keys: {'X_test', 'X', 'fold_groups_param', 'fix_imbalance', '_ml_usecase', 'target_param', 'n_jobs_param', 'exp_name_log', 'y_test', 'fold_generator', 'X_train', 'logging_param', 'log_plots_param', 'y_train', 'fold_shuffle_param', 'is_multiclass', 'seed', 'USI', 'exp_id', 'idx', 'html_param', '_available_plots', 'pipeline', 'memory', 'gpu_param', 'gpu_n_jobs_param', 'y', 'data'}
2025-11-16 05:30:36,294:INFO:Checking environment
2025-11-16 05:30:36,294:INFO:python_version: 3.11.14
2025-11-16 05:30:36,294:INFO:python_build: ('main', 'Nov 16 2025 04:28:49')
2025-11-16 05:30:36,294:INFO:machine: x86_64
2025-11-16 05:30:36,298:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:30:36,298:INFO:Memory: svmem(total=8345706496, available=7487971328, percent=10.3, used=857735168, free=1237458944, active=983064576, inactive=5616717824, buffers=127963136, cached=6435110912, shared=647168, slab=450412544)
2025-11-16 05:30:36,303:INFO:Physical Core: 4
2025-11-16 05:30:36,303:INFO:Logical Core: 4
2025-11-16 05:30:36,303:INFO:Checking libraries
2025-11-16 05:30:36,303:INFO:System:
2025-11-16 05:30:36,303:INFO:    python: 3.11.14 (main, Nov 16 2025, 04:28:49) [GCC 13.3.0]
2025-11-16 05:30:36,303:INFO:executable: /home/jules/.pyenv/versions/3.11.14/bin/python
2025-11-16 05:30:36,303:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:30:36,303:INFO:PyCaret required dependencies:
2025-11-16 05:30:36,368:INFO:                 pip: 24.0
2025-11-16 05:30:36,368:INFO:          setuptools: 79.0.1
2025-11-16 05:30:36,368:INFO:             pycaret: 3.3.2
2025-11-16 05:30:36,369:INFO:             IPython: 9.7.0
2025-11-16 05:30:36,369:INFO:          ipywidgets: 8.1.8
2025-11-16 05:30:36,369:INFO:                tqdm: 4.67.1
2025-11-16 05:30:36,369:INFO:               numpy: 1.26.4
2025-11-16 05:30:36,369:INFO:              pandas: 2.1.4
2025-11-16 05:30:36,369:INFO:              jinja2: 3.1.6
2025-11-16 05:30:36,369:INFO:               scipy: 1.11.4
2025-11-16 05:30:36,369:INFO:              joblib: 1.3.2
2025-11-16 05:30:36,369:INFO:             sklearn: 1.4.2
2025-11-16 05:30:36,369:INFO:                pyod: 2.0.5
2025-11-16 05:30:36,369:INFO:            imblearn: 0.14.0
2025-11-16 05:30:36,369:INFO:   category_encoders: 2.7.0
2025-11-16 05:30:36,369:INFO:            lightgbm: 4.6.0
2025-11-16 05:30:36,369:INFO:               numba: 0.62.1
2025-11-16 05:30:36,369:INFO:            requests: 2.32.5
2025-11-16 05:30:36,369:INFO:          matplotlib: 3.7.5
2025-11-16 05:30:36,369:INFO:          scikitplot: 0.3.7
2025-11-16 05:30:36,369:INFO:         yellowbrick: 1.5
2025-11-16 05:30:36,369:INFO:              plotly: 6.4.0
2025-11-16 05:30:36,369:INFO:    plotly-resampler: Not installed
2025-11-16 05:30:36,369:INFO:             kaleido: 1.2.0
2025-11-16 05:30:36,369:INFO:           schemdraw: 0.15
2025-11-16 05:30:36,369:INFO:         statsmodels: 0.14.5
2025-11-16 05:30:36,369:INFO:              sktime: 0.26.0
2025-11-16 05:30:36,369:INFO:               tbats: 1.1.3
2025-11-16 05:30:36,369:INFO:            pmdarima: 2.0.4
2025-11-16 05:30:36,369:INFO:              psutil: 7.1.3
2025-11-16 05:30:36,369:INFO:          markupsafe: 3.0.3
2025-11-16 05:30:36,369:INFO:             pickle5: Not installed
2025-11-16 05:30:36,369:INFO:         cloudpickle: 3.1.2
2025-11-16 05:30:36,369:INFO:         deprecation: 2.1.0
2025-11-16 05:30:36,369:INFO:              xxhash: 3.6.0
2025-11-16 05:30:36,369:INFO:           wurlitzer: 3.1.1
2025-11-16 05:30:36,369:INFO:PyCaret optional dependencies:
2025-11-16 05:30:36,414:INFO:                shap: 0.49.1
2025-11-16 05:30:36,414:INFO:           interpret: Not installed
2025-11-16 05:30:36,414:INFO:                umap: Not installed
2025-11-16 05:30:36,414:INFO:     ydata_profiling: Not installed
2025-11-16 05:30:36,414:INFO:  explainerdashboard: Not installed
2025-11-16 05:30:36,414:INFO:             autoviz: Not installed
2025-11-16 05:30:36,414:INFO:           fairlearn: Not installed
2025-11-16 05:30:36,414:INFO:          deepchecks: Not installed
2025-11-16 05:30:36,414:INFO:             xgboost: Not installed
2025-11-16 05:30:36,414:INFO:            catboost: Not installed
2025-11-16 05:30:36,414:INFO:              kmodes: Not installed
2025-11-16 05:30:36,414:INFO:             mlxtend: Not installed
2025-11-16 05:30:36,414:INFO:       statsforecast: Not installed
2025-11-16 05:30:36,415:INFO:        tune_sklearn: Not installed
2025-11-16 05:30:36,415:INFO:                 ray: Not installed
2025-11-16 05:30:36,415:INFO:            hyperopt: Not installed
2025-11-16 05:30:36,415:INFO:              optuna: Not installed
2025-11-16 05:30:36,415:INFO:               skopt: Not installed
2025-11-16 05:30:36,415:INFO:              mlflow: Not installed
2025-11-16 05:30:36,415:INFO:              gradio: Not installed
2025-11-16 05:30:36,415:INFO:             fastapi: Not installed
2025-11-16 05:30:36,415:INFO:             uvicorn: Not installed
2025-11-16 05:30:36,415:INFO:              m2cgen: Not installed
2025-11-16 05:30:36,415:INFO:           evidently: Not installed
2025-11-16 05:30:36,415:INFO:               fugue: Not installed
2025-11-16 05:30:36,415:INFO:           streamlit: Not installed
2025-11-16 05:30:36,415:INFO:             prophet: Not installed
2025-11-16 05:30:36,415:INFO:None
2025-11-16 05:30:36,415:INFO:Set up data.
2025-11-16 05:30:36,422:INFO:Set up folding strategy.
2025-11-16 05:30:36,422:INFO:Set up train/test split.
2025-11-16 05:30:36,430:INFO:Set up index.
2025-11-16 05:30:36,430:INFO:Assigning column types.
2025-11-16 05:30:36,435:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 05:30:36,502:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,507:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,630:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,668:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 05:30:36,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,841:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:30:36,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,878:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 05:30:36,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:36,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,097:INFO:Preparing preprocessing pipeline...
2025-11-16 05:30:37,099:INFO:Set up label encoding.
2025-11-16 05:30:37,099:INFO:Set up simple imputation.
2025-11-16 05:30:37,139:INFO:Finished creating preprocessing pipeline.
2025-11-16 05:30:37,144:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-16 05:30:37,144:INFO:Creating final display dataframe.
2025-11-16 05:30:37,249:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                13
2                   Target type        Multiclass
3                Target mapping           24.0: 0
4           Original data shape         (100, 14)
5        Transformed data shape         (100, 14)
6   Transformed train set shape          (70, 14)
7    Transformed test set shape          (30, 14)
8              Numeric features                13
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              2854
2025-11-16 05:30:37,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:30:37,487:INFO:setup() successfully completed in 1.2s...............
2025-11-16 05:30:37,487:INFO:Initializing compare_models()
2025-11-16 05:30:37,487:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 05:30:37,487:INFO:Checking exceptions
2025-11-16 05:30:37,493:INFO:Preparing display monitor
2025-11-16 05:30:37,496:INFO:Initializing Logistic Regression
2025-11-16 05:30:37,496:INFO:Total runtime is 2.006689707438151e-06 minutes
2025-11-16 05:30:37,496:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:37,496:INFO:Initializing create_model()
2025-11-16 05:30:37,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:37,496:INFO:Checking exceptions
2025-11-16 05:30:37,496:INFO:Importing libraries
2025-11-16 05:30:37,496:INFO:Copying training dataset
2025-11-16 05:30:37,502:INFO:Defining folds
2025-11-16 05:30:37,502:INFO:Declaring metric variables
2025-11-16 05:30:37,502:INFO:Importing untrained model
2025-11-16 05:30:37,502:INFO:Logistic Regression Imported successfully
2025-11-16 05:30:37,503:INFO:Starting cross validation
2025-11-16 05:30:37,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:41,542:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:30:41,555:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:30:41,555:INFO:Initializing create_model()
2025-11-16 05:30:41,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:41,555:INFO:Checking exceptions
2025-11-16 05:30:41,555:INFO:Importing libraries
2025-11-16 05:30:41,556:INFO:Copying training dataset
2025-11-16 05:30:41,563:INFO:Defining folds
2025-11-16 05:30:41,563:INFO:Declaring metric variables
2025-11-16 05:30:41,563:INFO:Importing untrained model
2025-11-16 05:30:41,564:INFO:Logistic Regression Imported successfully
2025-11-16 05:30:41,564:INFO:Starting cross validation
2025-11-16 05:30:41,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:41,646:ERROR:create_model() for lr raised an exception or returned all 0.0:
2025-11-16 05:30:41,649:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:30:41,649:INFO:Initializing K Neighbors Classifier
2025-11-16 05:30:41,649:INFO:Total runtime is 0.06923284133275351 minutes
2025-11-16 05:30:41,650:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:41,650:INFO:Initializing create_model()
2025-11-16 05:30:41,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:41,650:INFO:Checking exceptions
2025-11-16 05:30:41,650:INFO:Importing libraries
2025-11-16 05:30:41,650:INFO:Copying training dataset
2025-11-16 05:30:41,655:INFO:Defining folds
2025-11-16 05:30:41,656:INFO:Declaring metric variables
2025-11-16 05:30:41,656:INFO:Importing untrained model
2025-11-16 05:30:41,656:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:30:41,656:INFO:Starting cross validation
2025-11-16 05:30:41,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:41,741:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,742:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,742:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,748:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,748:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,748:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,749:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,751:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,751:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,754:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,754:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,755:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,755:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,757:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,758:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,758:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,758:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,758:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,759:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,760:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,761:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,761:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,761:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,761:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,763:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,765:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,765:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,767:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,819:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,820:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,822:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,822:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,824:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,824:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,826:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,827:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,828:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,829:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,830:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,831:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,832:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,832:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,833:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,833:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,835:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,835:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,836:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,839:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,842:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,845:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,845:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,847:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:41,890:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,891:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,897:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,897:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:41,900:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,900:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,900:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,901:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:41,902:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,902:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:41,908:INFO:Calculating mean and std
2025-11-16 05:30:41,909:INFO:Creating metrics dataframe
2025-11-16 05:30:41,912:INFO:Uploading results into container
2025-11-16 05:30:41,913:INFO:Uploading model into container now
2025-11-16 05:30:41,914:INFO:_master_model_container: 1
2025-11-16 05:30:41,914:INFO:_display_container: 2
2025-11-16 05:30:41,914:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:30:41,914:INFO:create_model() successfully completed......................................
2025-11-16 05:30:42,052:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:42,052:INFO:Creating metrics dataframe
2025-11-16 05:30:42,056:INFO:Initializing Naive Bayes
2025-11-16 05:30:42,056:INFO:Total runtime is 0.0760033925374349 minutes
2025-11-16 05:30:42,056:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:42,056:INFO:Initializing create_model()
2025-11-16 05:30:42,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:42,056:INFO:Checking exceptions
2025-11-16 05:30:42,056:INFO:Importing libraries
2025-11-16 05:30:42,056:INFO:Copying training dataset
2025-11-16 05:30:42,061:INFO:Defining folds
2025-11-16 05:30:42,061:INFO:Declaring metric variables
2025-11-16 05:30:42,062:INFO:Importing untrained model
2025-11-16 05:30:42,062:INFO:Naive Bayes Imported successfully
2025-11-16 05:30:42,062:INFO:Starting cross validation
2025-11-16 05:30:42,063:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:42,100:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,102:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,102:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,104:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,105:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,106:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,107:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,108:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,108:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,110:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,111:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,111:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,111:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,112:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,114:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,114:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,115:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,117:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,117:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,117:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,119:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,120:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,126:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,127:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,129:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,138:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,140:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,140:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,140:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,142:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,142:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,143:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,145:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,145:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,146:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,148:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,148:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,149:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,149:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,150:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,152:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,153:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,153:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,154:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,157:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,160:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,160:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,162:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,172:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,173:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,174:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,175:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,177:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,178:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,180:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,181:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,183:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,183:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,184:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,184:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,185:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,186:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,196:INFO:Calculating mean and std
2025-11-16 05:30:42,197:INFO:Creating metrics dataframe
2025-11-16 05:30:42,199:INFO:Uploading results into container
2025-11-16 05:30:42,200:INFO:Uploading model into container now
2025-11-16 05:30:42,200:INFO:_master_model_container: 2
2025-11-16 05:30:42,200:INFO:_display_container: 2
2025-11-16 05:30:42,201:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 05:30:42,201:INFO:create_model() successfully completed......................................
2025-11-16 05:30:42,310:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:42,310:INFO:Creating metrics dataframe
2025-11-16 05:30:42,314:INFO:Initializing Decision Tree Classifier
2025-11-16 05:30:42,314:INFO:Total runtime is 0.08031059503555299 minutes
2025-11-16 05:30:42,314:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:42,315:INFO:Initializing create_model()
2025-11-16 05:30:42,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:42,315:INFO:Checking exceptions
2025-11-16 05:30:42,315:INFO:Importing libraries
2025-11-16 05:30:42,315:INFO:Copying training dataset
2025-11-16 05:30:42,320:INFO:Defining folds
2025-11-16 05:30:42,320:INFO:Declaring metric variables
2025-11-16 05:30:42,320:INFO:Importing untrained model
2025-11-16 05:30:42,321:INFO:Decision Tree Classifier Imported successfully
2025-11-16 05:30:42,321:INFO:Starting cross validation
2025-11-16 05:30:42,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:42,359:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,359:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,361:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,361:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,361:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,362:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,363:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,364:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,364:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,364:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,366:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,367:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,367:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,368:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,369:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,370:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,370:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,370:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,370:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,371:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,372:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,372:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,372:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,373:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,373:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,374:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,374:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,375:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,394:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,394:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,395:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,396:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,397:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,398:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,398:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,399:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,399:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,400:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,401:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,402:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,402:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,403:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,404:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,405:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,405:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,405:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,405:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,409:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,409:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,410:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,411:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,427:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,427:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:42,429:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,429:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,432:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,432:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,435:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,435:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,440:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,440:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,450:INFO:Calculating mean and std
2025-11-16 05:30:42,451:INFO:Creating metrics dataframe
2025-11-16 05:30:42,453:INFO:Uploading results into container
2025-11-16 05:30:42,454:INFO:Uploading model into container now
2025-11-16 05:30:42,454:INFO:_master_model_container: 3
2025-11-16 05:30:42,454:INFO:_display_container: 2
2025-11-16 05:30:42,455:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-16 05:30:42,455:INFO:create_model() successfully completed......................................
2025-11-16 05:30:42,565:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:42,565:INFO:Creating metrics dataframe
2025-11-16 05:30:42,568:INFO:Initializing SVM - Linear Kernel
2025-11-16 05:30:42,568:INFO:Total runtime is 0.08454753557840984 minutes
2025-11-16 05:30:42,569:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:42,569:INFO:Initializing create_model()
2025-11-16 05:30:42,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:42,569:INFO:Checking exceptions
2025-11-16 05:30:42,569:INFO:Importing libraries
2025-11-16 05:30:42,569:INFO:Copying training dataset
2025-11-16 05:30:42,574:INFO:Defining folds
2025-11-16 05:30:42,574:INFO:Declaring metric variables
2025-11-16 05:30:42,574:INFO:Importing untrained model
2025-11-16 05:30:42,574:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:30:42,575:INFO:Starting cross validation
2025-11-16 05:30:42,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:42,642:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:30:42,644:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:30:42,644:INFO:Initializing create_model()
2025-11-16 05:30:42,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:42,645:INFO:Checking exceptions
2025-11-16 05:30:42,645:INFO:Importing libraries
2025-11-16 05:30:42,645:INFO:Copying training dataset
2025-11-16 05:30:42,650:INFO:Defining folds
2025-11-16 05:30:42,650:INFO:Declaring metric variables
2025-11-16 05:30:42,650:INFO:Importing untrained model
2025-11-16 05:30:42,651:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:30:42,651:INFO:Starting cross validation
2025-11-16 05:30:42,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:42,720:ERROR:create_model() for svm raised an exception or returned all 0.0:
2025-11-16 05:30:42,722:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:30:42,723:INFO:Initializing Ridge Classifier
2025-11-16 05:30:42,723:INFO:Total runtime is 0.08712082306543988 minutes
2025-11-16 05:30:42,723:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:42,723:INFO:Initializing create_model()
2025-11-16 05:30:42,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:42,724:INFO:Checking exceptions
2025-11-16 05:30:42,724:INFO:Importing libraries
2025-11-16 05:30:42,724:INFO:Copying training dataset
2025-11-16 05:30:42,729:INFO:Defining folds
2025-11-16 05:30:42,729:INFO:Declaring metric variables
2025-11-16 05:30:42,729:INFO:Importing untrained model
2025-11-16 05:30:42,730:INFO:Ridge Classifier Imported successfully
2025-11-16 05:30:42,730:INFO:Starting cross validation
2025-11-16 05:30:42,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:42,788:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,788:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,788:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,789:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,790:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,790:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,790:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,791:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,793:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,793:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,793:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,794:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,796:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,797:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,797:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,798:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,799:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,799:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,799:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,800:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,800:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,800:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,801:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,801:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,801:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,802:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,802:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,803:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,824:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,824:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,826:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,826:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,828:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,829:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,829:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,829:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,830:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,831:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,832:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,833:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,833:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,835:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,835:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,835:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,836:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,836:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,837:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,838:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,838:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,839:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,839:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,841:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,841:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,841:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,843:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,860:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,861:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:42,862:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,862:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,865:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,865:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,869:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,869:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:42,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:42,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:42,884:INFO:Calculating mean and std
2025-11-16 05:30:42,884:INFO:Creating metrics dataframe
2025-11-16 05:30:42,887:INFO:Uploading results into container
2025-11-16 05:30:42,887:INFO:Uploading model into container now
2025-11-16 05:30:42,888:INFO:_master_model_container: 4
2025-11-16 05:30:42,888:INFO:_display_container: 2
2025-11-16 05:30:42,888:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-16 05:30:42,888:INFO:create_model() successfully completed......................................
2025-11-16 05:30:42,998:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:42,998:INFO:Creating metrics dataframe
2025-11-16 05:30:43,002:INFO:Initializing Random Forest Classifier
2025-11-16 05:30:43,003:INFO:Total runtime is 0.09178470770517987 minutes
2025-11-16 05:30:43,003:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:43,003:INFO:Initializing create_model()
2025-11-16 05:30:43,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:43,003:INFO:Checking exceptions
2025-11-16 05:30:43,003:INFO:Importing libraries
2025-11-16 05:30:43,003:INFO:Copying training dataset
2025-11-16 05:30:43,009:INFO:Defining folds
2025-11-16 05:30:43,009:INFO:Declaring metric variables
2025-11-16 05:30:43,009:INFO:Importing untrained model
2025-11-16 05:30:43,010:INFO:Random Forest Classifier Imported successfully
2025-11-16 05:30:43,010:INFO:Starting cross validation
2025-11-16 05:30:43,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:43,266:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,268:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,275:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,277:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,277:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,278:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,281:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,284:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,287:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,287:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,289:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,294:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,300:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,301:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,303:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,305:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,306:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,306:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,308:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,309:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,311:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,311:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,313:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,530:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,532:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,532:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,534:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,536:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,538:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,539:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,542:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,543:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,543:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,547:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,566:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,568:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,573:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,576:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,582:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,583:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,588:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,591:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,594:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,594:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,596:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,886:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,888:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,892:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,895:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,895:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:43,897:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,898:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,898:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,900:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,901:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,904:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:43,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:43,909:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:43,911:INFO:Calculating mean and std
2025-11-16 05:30:43,911:INFO:Creating metrics dataframe
2025-11-16 05:30:43,914:INFO:Uploading results into container
2025-11-16 05:30:43,914:INFO:Uploading model into container now
2025-11-16 05:30:43,915:INFO:_master_model_container: 5
2025-11-16 05:30:43,915:INFO:_display_container: 2
2025-11-16 05:30:43,915:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-16 05:30:43,915:INFO:create_model() successfully completed......................................
2025-11-16 05:30:44,024:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:44,024:INFO:Creating metrics dataframe
2025-11-16 05:30:44,028:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 05:30:44,028:INFO:Total runtime is 0.10887651840845745 minutes
2025-11-16 05:30:44,029:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:44,029:INFO:Initializing create_model()
2025-11-16 05:30:44,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,029:INFO:Checking exceptions
2025-11-16 05:30:44,029:INFO:Importing libraries
2025-11-16 05:30:44,029:INFO:Copying training dataset
2025-11-16 05:30:44,035:INFO:Defining folds
2025-11-16 05:30:44,035:INFO:Declaring metric variables
2025-11-16 05:30:44,035:INFO:Importing untrained model
2025-11-16 05:30:44,035:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:30:44,035:INFO:Starting cross validation
2025-11-16 05:30:44,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,098:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:30:44,099:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:30:44,100:INFO:Initializing create_model()
2025-11-16 05:30:44,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,100:INFO:Checking exceptions
2025-11-16 05:30:44,100:INFO:Importing libraries
2025-11-16 05:30:44,100:INFO:Copying training dataset
2025-11-16 05:30:44,105:INFO:Defining folds
2025-11-16 05:30:44,105:INFO:Declaring metric variables
2025-11-16 05:30:44,105:INFO:Importing untrained model
2025-11-16 05:30:44,106:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:30:44,106:INFO:Starting cross validation
2025-11-16 05:30:44,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,162:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-11-16 05:30:44,165:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:30:44,165:INFO:Initializing Ada Boost Classifier
2025-11-16 05:30:44,165:INFO:Total runtime is 0.11115872462590537 minutes
2025-11-16 05:30:44,165:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:44,166:INFO:Initializing create_model()
2025-11-16 05:30:44,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,166:INFO:Checking exceptions
2025-11-16 05:30:44,166:INFO:Importing libraries
2025-11-16 05:30:44,166:INFO:Copying training dataset
2025-11-16 05:30:44,171:INFO:Defining folds
2025-11-16 05:30:44,171:INFO:Declaring metric variables
2025-11-16 05:30:44,171:INFO:Importing untrained model
2025-11-16 05:30:44,171:INFO:Ada Boost Classifier Imported successfully
2025-11-16 05:30:44,172:INFO:Starting cross validation
2025-11-16 05:30:44,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,198:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,211:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,213:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,213:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,216:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,217:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,217:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,218:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,221:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,223:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,223:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,223:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,224:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,226:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,227:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,228:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,228:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,230:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,233:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,236:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,241:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,245:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,246:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,249:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,251:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,254:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,254:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,255:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,257:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,258:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,259:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,262:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,262:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,262:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,263:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,265:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,265:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,265:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,266:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,267:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,268:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,272:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:30:44,287:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,289:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,291:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,292:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,292:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,295:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,295:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,298:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,298:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,300:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,301:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,302:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,303:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,309:INFO:Calculating mean and std
2025-11-16 05:30:44,309:INFO:Creating metrics dataframe
2025-11-16 05:30:44,311:INFO:Uploading results into container
2025-11-16 05:30:44,312:INFO:Uploading model into container now
2025-11-16 05:30:44,312:INFO:_master_model_container: 6
2025-11-16 05:30:44,312:INFO:_display_container: 2
2025-11-16 05:30:44,313:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 05:30:44,313:INFO:create_model() successfully completed......................................
2025-11-16 05:30:44,420:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:44,421:INFO:Creating metrics dataframe
2025-11-16 05:30:44,424:INFO:Initializing Gradient Boosting Classifier
2025-11-16 05:30:44,424:INFO:Total runtime is 0.11547760168711346 minutes
2025-11-16 05:30:44,424:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:44,425:INFO:Initializing create_model()
2025-11-16 05:30:44,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,425:INFO:Checking exceptions
2025-11-16 05:30:44,425:INFO:Importing libraries
2025-11-16 05:30:44,425:INFO:Copying training dataset
2025-11-16 05:30:44,430:INFO:Defining folds
2025-11-16 05:30:44,430:INFO:Declaring metric variables
2025-11-16 05:30:44,430:INFO:Importing untrained model
2025-11-16 05:30:44,430:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:30:44,430:INFO:Starting cross validation
2025-11-16 05:30:44,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,501:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:30:44,502:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:30:44,503:INFO:Initializing create_model()
2025-11-16 05:30:44,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,503:INFO:Checking exceptions
2025-11-16 05:30:44,503:INFO:Importing libraries
2025-11-16 05:30:44,503:INFO:Copying training dataset
2025-11-16 05:30:44,508:INFO:Defining folds
2025-11-16 05:30:44,509:INFO:Declaring metric variables
2025-11-16 05:30:44,509:INFO:Importing untrained model
2025-11-16 05:30:44,509:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:30:44,509:INFO:Starting cross validation
2025-11-16 05:30:44,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,577:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2025-11-16 05:30:44,580:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:30:44,580:INFO:Initializing Linear Discriminant Analysis
2025-11-16 05:30:44,581:INFO:Total runtime is 0.11808478434880576 minutes
2025-11-16 05:30:44,581:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:44,581:INFO:Initializing create_model()
2025-11-16 05:30:44,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,581:INFO:Checking exceptions
2025-11-16 05:30:44,581:INFO:Importing libraries
2025-11-16 05:30:44,581:INFO:Copying training dataset
2025-11-16 05:30:44,587:INFO:Defining folds
2025-11-16 05:30:44,587:INFO:Declaring metric variables
2025-11-16 05:30:44,587:INFO:Importing untrained model
2025-11-16 05:30:44,587:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 05:30:44,588:INFO:Starting cross validation
2025-11-16 05:30:44,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:44,628:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,628:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,629:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,630:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,630:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,631:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,632:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,633:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,633:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,633:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,634:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,636:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,636:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,636:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,637:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,638:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,639:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,639:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,639:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,639:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,640:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,640:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,640:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,641:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,644:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,663:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,665:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,665:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,666:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,667:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,667:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,668:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,669:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,670:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,670:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,671:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,671:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,673:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,673:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,674:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,674:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,674:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,676:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,678:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,678:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,679:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,680:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,682:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,698:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,699:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:44,699:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,701:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,703:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,704:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,706:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,707:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:44,709:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,709:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,710:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,710:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:44,711:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,712:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:44,720:INFO:Calculating mean and std
2025-11-16 05:30:44,721:INFO:Creating metrics dataframe
2025-11-16 05:30:44,724:INFO:Uploading results into container
2025-11-16 05:30:44,724:INFO:Uploading model into container now
2025-11-16 05:30:44,725:INFO:_master_model_container: 7
2025-11-16 05:30:44,725:INFO:_display_container: 2
2025-11-16 05:30:44,725:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 05:30:44,725:INFO:create_model() successfully completed......................................
2025-11-16 05:30:44,830:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:44,830:INFO:Creating metrics dataframe
2025-11-16 05:30:44,833:INFO:Initializing Extra Trees Classifier
2025-11-16 05:30:44,834:INFO:Total runtime is 0.12230151096979779 minutes
2025-11-16 05:30:44,834:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:44,834:INFO:Initializing create_model()
2025-11-16 05:30:44,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:44,834:INFO:Checking exceptions
2025-11-16 05:30:44,834:INFO:Importing libraries
2025-11-16 05:30:44,834:INFO:Copying training dataset
2025-11-16 05:30:44,839:INFO:Defining folds
2025-11-16 05:30:44,839:INFO:Declaring metric variables
2025-11-16 05:30:44,839:INFO:Importing untrained model
2025-11-16 05:30:44,839:INFO:Extra Trees Classifier Imported successfully
2025-11-16 05:30:44,840:INFO:Starting cross validation
2025-11-16 05:30:44,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:45,056:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,058:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,062:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,063:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,065:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,065:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,067:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,068:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,068:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,069:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,070:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,070:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,072:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,073:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,074:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,075:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,076:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,077:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,079:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,079:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,080:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,081:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,082:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,086:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,089:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,092:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,092:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,094:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,273:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,273:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,275:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,276:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,278:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,281:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,282:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,283:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,285:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,285:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,285:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,286:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,286:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,287:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,288:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,289:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,293:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,297:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,300:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,303:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,306:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,309:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,312:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,312:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,314:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,531:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,533:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,536:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,539:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,542:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:45,542:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,543:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,544:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,547:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,550:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,553:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,553:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,555:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,559:INFO:Calculating mean and std
2025-11-16 05:30:45,559:INFO:Creating metrics dataframe
2025-11-16 05:30:45,562:INFO:Uploading results into container
2025-11-16 05:30:45,562:INFO:Uploading model into container now
2025-11-16 05:30:45,562:INFO:_master_model_container: 8
2025-11-16 05:30:45,563:INFO:_display_container: 2
2025-11-16 05:30:45,563:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-16 05:30:45,563:INFO:create_model() successfully completed......................................
2025-11-16 05:30:45,670:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:45,670:INFO:Creating metrics dataframe
2025-11-16 05:30:45,674:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 05:30:45,674:INFO:Total runtime is 0.13630893230438235 minutes
2025-11-16 05:30:45,674:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:45,674:INFO:Initializing create_model()
2025-11-16 05:30:45,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:45,675:INFO:Checking exceptions
2025-11-16 05:30:45,675:INFO:Importing libraries
2025-11-16 05:30:45,675:INFO:Copying training dataset
2025-11-16 05:30:45,679:INFO:Defining folds
2025-11-16 05:30:45,679:INFO:Declaring metric variables
2025-11-16 05:30:45,679:INFO:Importing untrained model
2025-11-16 05:30:45,680:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 05:30:45,681:INFO:Starting cross validation
2025-11-16 05:30:45,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:45,902:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:45,904:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,919:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,926:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,929:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,929:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,931:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,942:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:45,950:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,953:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,956:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:45,959:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,959:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:45,961:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:45,998:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:45,999:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,010:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,013:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,018:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,019:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,022:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,022:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,023:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,024:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,026:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,029:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,029:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,031:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,174:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,188:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,191:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,198:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,200:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,202:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,202:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,204:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,224:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,270:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,281:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,282:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,283:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,286:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,288:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,291:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,294:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,295:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,301:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,367:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,373:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,374:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:30:46,376:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,378:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,380:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,381:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,383:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,384:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,384:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,386:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,386:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,387:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,389:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,395:INFO:Calculating mean and std
2025-11-16 05:30:46,396:INFO:Creating metrics dataframe
2025-11-16 05:30:46,398:INFO:Uploading results into container
2025-11-16 05:30:46,399:INFO:Uploading model into container now
2025-11-16 05:30:46,399:INFO:_master_model_container: 9
2025-11-16 05:30:46,399:INFO:_display_container: 2
2025-11-16 05:30:46,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 05:30:46,400:INFO:create_model() successfully completed......................................
2025-11-16 05:30:46,504:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:46,504:INFO:Creating metrics dataframe
2025-11-16 05:30:46,507:INFO:Initializing Dummy Classifier
2025-11-16 05:30:46,507:INFO:Total runtime is 0.15019787947336835 minutes
2025-11-16 05:30:46,508:INFO:SubProcess create_model() called ==================================
2025-11-16 05:30:46,508:INFO:Initializing create_model()
2025-11-16 05:30:46,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f12fc2c3f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:46,508:INFO:Checking exceptions
2025-11-16 05:30:46,508:INFO:Importing libraries
2025-11-16 05:30:46,508:INFO:Copying training dataset
2025-11-16 05:30:46,513:INFO:Defining folds
2025-11-16 05:30:46,513:INFO:Declaring metric variables
2025-11-16 05:30:46,513:INFO:Importing untrained model
2025-11-16 05:30:46,513:INFO:Dummy Classifier Imported successfully
2025-11-16 05:30:46,513:INFO:Starting cross validation
2025-11-16 05:30:46,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:30:46,544:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,546:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,547:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,549:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,550:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,552:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,553:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,554:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,555:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,555:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,555:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,555:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,556:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,556:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,557:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,557:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,557:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,559:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,560:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,562:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,563:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,565:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,565:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,567:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,569:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,569:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,571:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,574:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,576:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,577:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,578:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,579:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,582:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,587:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,587:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,588:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,588:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,588:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,590:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,590:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,591:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,593:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,594:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,595:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,596:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,596:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,599:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,599:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,601:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,606:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,607:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,608:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:30:46,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,611:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,613:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,614:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,615:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:30:46,617:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,617:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,618:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,618:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:30:46,619:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,620:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:30:46,632:INFO:Calculating mean and std
2025-11-16 05:30:46,633:INFO:Creating metrics dataframe
2025-11-16 05:30:46,635:INFO:Uploading results into container
2025-11-16 05:30:46,635:INFO:Uploading model into container now
2025-11-16 05:30:46,636:INFO:_master_model_container: 10
2025-11-16 05:30:46,636:INFO:_display_container: 2
2025-11-16 05:30:46,636:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-16 05:30:46,636:INFO:create_model() successfully completed......................................
2025-11-16 05:30:46,741:INFO:SubProcess create_model() end ==================================
2025-11-16 05:30:46,741:INFO:Creating metrics dataframe
2025-11-16 05:30:46,744:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-16 05:30:46,746:INFO:Initializing create_model()
2025-11-16 05:30:46,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f130ec5dc10>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:30:46,746:INFO:Checking exceptions
2025-11-16 05:30:46,747:INFO:Importing libraries
2025-11-16 05:30:46,747:INFO:Copying training dataset
2025-11-16 05:30:46,752:INFO:Defining folds
2025-11-16 05:30:46,752:INFO:Declaring metric variables
2025-11-16 05:30:46,752:INFO:Importing untrained model
2025-11-16 05:30:46,752:INFO:Declaring custom model
2025-11-16 05:30:46,753:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:30:46,753:INFO:Cross validation set to False
2025-11-16 05:30:46,753:INFO:Fitting Model
2025-11-16 05:30:46,766:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:30:46,767:INFO:create_model() successfully completed......................................
2025-11-16 05:30:46,877:INFO:_master_model_container: 10
2025-11-16 05:30:46,877:INFO:_display_container: 2
2025-11-16 05:30:46,877:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:30:46,877:INFO:compare_models() successfully completed......................................
2025-11-16 05:40:25,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:40:25,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:40:25,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:40:25,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:40:28,637:INFO:PyCaret ClassificationExperiment
2025-11-16 05:40:28,637:INFO:Logging name: clf-default-name
2025-11-16 05:40:28,637:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 05:40:28,637:INFO:version 3.3.2
2025-11-16 05:40:28,637:INFO:Initializing setup()
2025-11-16 05:40:28,638:INFO:self.USI: 461d
2025-11-16 05:40:28,638:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'pipeline', 'y', 'fix_imbalance', 'gpu_param', 'idx', '_ml_usecase', 'logging_param', '_available_plots', 'data', 'X', 'y_test', 'X_test', 'gpu_n_jobs_param', 'y_train', 'USI', 'is_multiclass', 'html_param', 'fold_groups_param', 'seed', 'memory', 'X_train', 'fold_generator', 'target_param', 'n_jobs_param', 'fold_shuffle_param', 'log_plots_param'}
2025-11-16 05:40:28,638:INFO:Checking environment
2025-11-16 05:40:28,638:INFO:python_version: 3.11.14
2025-11-16 05:40:28,638:INFO:python_build: ('main', 'Nov 16 2025 04:28:49')
2025-11-16 05:40:28,639:INFO:machine: x86_64
2025-11-16 05:40:28,652:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:40:28,653:INFO:Memory: svmem(total=8345706496, available=7482441728, percent=10.3, used=863264768, free=1229901824, active=1117667328, inactive=5494194176, buffers=128266240, cached=6436835328, shared=647168, slab=450789376)
2025-11-16 05:40:28,655:INFO:Physical Core: 4
2025-11-16 05:40:28,656:INFO:Logical Core: 4
2025-11-16 05:40:28,656:INFO:Checking libraries
2025-11-16 05:40:28,656:INFO:System:
2025-11-16 05:40:28,656:INFO:    python: 3.11.14 (main, Nov 16 2025, 04:28:49) [GCC 13.3.0]
2025-11-16 05:40:28,656:INFO:executable: /home/jules/.pyenv/versions/3.11.14/bin/python
2025-11-16 05:40:28,656:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:40:28,657:INFO:PyCaret required dependencies:
2025-11-16 05:40:28,761:INFO:                 pip: 24.0
2025-11-16 05:40:28,762:INFO:          setuptools: 79.0.1
2025-11-16 05:40:28,762:INFO:             pycaret: 3.3.2
2025-11-16 05:40:28,762:INFO:             IPython: 9.7.0
2025-11-16 05:40:28,762:INFO:          ipywidgets: 8.1.8
2025-11-16 05:40:28,762:INFO:                tqdm: 4.67.1
2025-11-16 05:40:28,762:INFO:               numpy: 1.26.4
2025-11-16 05:40:28,762:INFO:              pandas: 2.1.4
2025-11-16 05:40:28,763:INFO:              jinja2: 3.1.6
2025-11-16 05:40:28,763:INFO:               scipy: 1.11.4
2025-11-16 05:40:28,763:INFO:              joblib: 1.3.2
2025-11-16 05:40:28,763:INFO:             sklearn: 1.4.2
2025-11-16 05:40:28,763:INFO:                pyod: 2.0.5
2025-11-16 05:40:28,763:INFO:            imblearn: 0.14.0
2025-11-16 05:40:28,763:INFO:   category_encoders: 2.7.0
2025-11-16 05:40:28,763:INFO:            lightgbm: 4.6.0
2025-11-16 05:40:28,763:INFO:               numba: 0.62.1
2025-11-16 05:40:28,763:INFO:            requests: 2.32.5
2025-11-16 05:40:28,763:INFO:          matplotlib: 3.7.5
2025-11-16 05:40:28,763:INFO:          scikitplot: 0.3.7
2025-11-16 05:40:28,764:INFO:         yellowbrick: 1.5
2025-11-16 05:40:28,764:INFO:              plotly: 6.4.0
2025-11-16 05:40:28,764:INFO:    plotly-resampler: Not installed
2025-11-16 05:40:28,764:INFO:             kaleido: 1.2.0
2025-11-16 05:40:28,764:INFO:           schemdraw: 0.15
2025-11-16 05:40:28,764:INFO:         statsmodels: 0.14.5
2025-11-16 05:40:28,764:INFO:              sktime: 0.26.0
2025-11-16 05:40:28,764:INFO:               tbats: 1.1.3
2025-11-16 05:40:28,764:INFO:            pmdarima: 2.0.4
2025-11-16 05:40:28,764:INFO:              psutil: 7.1.3
2025-11-16 05:40:28,764:INFO:          markupsafe: 3.0.3
2025-11-16 05:40:28,765:INFO:             pickle5: Not installed
2025-11-16 05:40:28,765:INFO:         cloudpickle: 3.1.2
2025-11-16 05:40:28,765:INFO:         deprecation: 2.1.0
2025-11-16 05:40:28,765:INFO:              xxhash: 3.6.0
2025-11-16 05:40:28,765:INFO:           wurlitzer: 3.1.1
2025-11-16 05:40:28,765:INFO:PyCaret optional dependencies:
2025-11-16 05:40:28,892:INFO:                shap: 0.49.1
2025-11-16 05:40:28,892:INFO:           interpret: Not installed
2025-11-16 05:40:28,893:INFO:                umap: Not installed
2025-11-16 05:40:28,893:INFO:     ydata_profiling: Not installed
2025-11-16 05:40:28,893:INFO:  explainerdashboard: Not installed
2025-11-16 05:40:28,893:INFO:             autoviz: Not installed
2025-11-16 05:40:28,893:INFO:           fairlearn: Not installed
2025-11-16 05:40:28,893:INFO:          deepchecks: Not installed
2025-11-16 05:40:28,894:INFO:             xgboost: Not installed
2025-11-16 05:40:28,895:INFO:            catboost: Not installed
2025-11-16 05:40:28,896:INFO:              kmodes: Not installed
2025-11-16 05:40:28,897:INFO:             mlxtend: Not installed
2025-11-16 05:40:28,897:INFO:       statsforecast: Not installed
2025-11-16 05:40:28,897:INFO:        tune_sklearn: Not installed
2025-11-16 05:40:28,897:INFO:                 ray: Not installed
2025-11-16 05:40:28,897:INFO:            hyperopt: Not installed
2025-11-16 05:40:28,897:INFO:              optuna: Not installed
2025-11-16 05:40:28,898:INFO:               skopt: Not installed
2025-11-16 05:40:28,898:INFO:              mlflow: Not installed
2025-11-16 05:40:28,898:INFO:              gradio: Not installed
2025-11-16 05:40:28,898:INFO:             fastapi: Not installed
2025-11-16 05:40:28,898:INFO:             uvicorn: Not installed
2025-11-16 05:40:28,898:INFO:              m2cgen: Not installed
2025-11-16 05:40:28,899:INFO:           evidently: Not installed
2025-11-16 05:40:28,899:INFO:               fugue: Not installed
2025-11-16 05:40:28,899:INFO:           streamlit: Not installed
2025-11-16 05:40:28,899:INFO:             prophet: Not installed
2025-11-16 05:40:28,899:INFO:None
2025-11-16 05:40:28,899:INFO:Set up data.
2025-11-16 05:40:28,918:INFO:Set up folding strategy.
2025-11-16 05:40:28,919:INFO:Set up train/test split.
2025-11-16 05:40:28,933:INFO:Set up index.
2025-11-16 05:40:28,933:INFO:Assigning column types.
2025-11-16 05:40:28,946:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 05:40:29,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:40:29,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:40:29,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:29,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:29,421:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:40:29,424:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:40:29,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:29,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:29,584:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 05:40:29,899:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:40:30,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:40:30,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,291:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 05:40:30,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:30,932:INFO:Preparing preprocessing pipeline...
2025-11-16 05:40:30,936:INFO:Set up label encoding.
2025-11-16 05:40:30,936:INFO:Set up simple imputation.
2025-11-16 05:40:31,024:INFO:Finished creating preprocessing pipeline.
2025-11-16 05:40:31,037:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-16 05:40:31,037:INFO:Creating final display dataframe.
2025-11-16 05:40:31,308:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                13
2                   Target type        Multiclass
3                Target mapping           24.0: 0
4           Original data shape         (100, 14)
5        Transformed data shape         (100, 14)
6   Transformed train set shape          (70, 14)
7    Transformed test set shape          (30, 14)
8              Numeric features                13
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              461d
2025-11-16 05:40:31,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:31,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:31,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:31,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:40:31,838:INFO:setup() successfully completed in 3.2s...............
2025-11-16 05:40:31,838:INFO:Initializing compare_models()
2025-11-16 05:40:31,838:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=False, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': False, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 05:40:31,838:INFO:Checking exceptions
2025-11-16 05:40:31,850:INFO:Preparing display monitor
2025-11-16 05:40:31,857:INFO:Initializing Logistic Regression
2025-11-16 05:40:31,857:INFO:Total runtime is 2.944469451904297e-06 minutes
2025-11-16 05:40:31,857:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:31,858:INFO:Initializing create_model()
2025-11-16 05:40:31,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:31,858:INFO:Checking exceptions
2025-11-16 05:40:31,858:INFO:Importing libraries
2025-11-16 05:40:31,858:INFO:Copying training dataset
2025-11-16 05:40:31,872:INFO:Defining folds
2025-11-16 05:40:31,872:INFO:Declaring metric variables
2025-11-16 05:40:31,872:INFO:Importing untrained model
2025-11-16 05:40:31,873:INFO:Logistic Regression Imported successfully
2025-11-16 05:40:31,874:INFO:Starting cross validation
2025-11-16 05:40:31,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:38,582:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:40:38,593:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:40:38,594:INFO:Initializing create_model()
2025-11-16 05:40:38,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:38,594:INFO:Checking exceptions
2025-11-16 05:40:38,594:INFO:Importing libraries
2025-11-16 05:40:38,594:INFO:Copying training dataset
2025-11-16 05:40:38,601:INFO:Defining folds
2025-11-16 05:40:38,601:INFO:Declaring metric variables
2025-11-16 05:40:38,601:INFO:Importing untrained model
2025-11-16 05:40:38,602:INFO:Logistic Regression Imported successfully
2025-11-16 05:40:38,605:INFO:Starting cross validation
2025-11-16 05:40:38,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:38,678:ERROR:create_model() for lr raised an exception or returned all 0.0:
2025-11-16 05:40:38,681:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:40:38,681:INFO:Initializing K Neighbors Classifier
2025-11-16 05:40:38,681:INFO:Total runtime is 0.11374621391296386 minutes
2025-11-16 05:40:38,682:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:38,682:INFO:Initializing create_model()
2025-11-16 05:40:38,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:38,682:INFO:Checking exceptions
2025-11-16 05:40:38,682:INFO:Importing libraries
2025-11-16 05:40:38,682:INFO:Copying training dataset
2025-11-16 05:40:38,687:INFO:Defining folds
2025-11-16 05:40:38,687:INFO:Declaring metric variables
2025-11-16 05:40:38,688:INFO:Importing untrained model
2025-11-16 05:40:38,688:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:40:38,688:INFO:Starting cross validation
2025-11-16 05:40:38,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:38,773:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,773:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,773:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,779:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,779:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,783:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,783:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,783:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,784:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,787:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,787:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,788:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,789:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,790:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,791:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,791:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,791:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,792:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,792:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,793:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,793:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,795:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,796:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,796:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,798:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,801:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,802:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,804:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,847:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,848:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,849:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,851:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,854:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,855:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,861:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,861:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,862:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,862:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,863:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,863:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,866:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,868:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,868:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,870:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,876:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,877:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,880:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,880:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,881:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,882:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,917:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,917:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:38,919:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,920:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,922:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,924:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,925:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,928:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,928:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,929:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:38,930:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,932:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,932:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:38,934:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:38,946:INFO:Calculating mean and std
2025-11-16 05:40:38,947:INFO:Creating metrics dataframe
2025-11-16 05:40:38,950:INFO:Uploading results into container
2025-11-16 05:40:38,950:INFO:Uploading model into container now
2025-11-16 05:40:38,951:INFO:_master_model_container: 1
2025-11-16 05:40:38,951:INFO:_display_container: 2
2025-11-16 05:40:38,952:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:40:38,952:INFO:create_model() successfully completed......................................
2025-11-16 05:40:39,097:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:39,097:INFO:Creating metrics dataframe
2025-11-16 05:40:39,100:INFO:Initializing Naive Bayes
2025-11-16 05:40:39,100:INFO:Total runtime is 0.12072441577911376 minutes
2025-11-16 05:40:39,100:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:39,101:INFO:Initializing create_model()
2025-11-16 05:40:39,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:39,101:INFO:Checking exceptions
2025-11-16 05:40:39,101:INFO:Importing libraries
2025-11-16 05:40:39,101:INFO:Copying training dataset
2025-11-16 05:40:39,106:INFO:Defining folds
2025-11-16 05:40:39,106:INFO:Declaring metric variables
2025-11-16 05:40:39,106:INFO:Importing untrained model
2025-11-16 05:40:39,106:INFO:Naive Bayes Imported successfully
2025-11-16 05:40:39,107:INFO:Starting cross validation
2025-11-16 05:40:39,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:39,149:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,151:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,154:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,157:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,160:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,160:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,162:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,162:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,163:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,165:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,165:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,169:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,170:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,170:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,170:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,173:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,173:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,173:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,175:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,176:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,176:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,176:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,176:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,178:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,178:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,179:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,179:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,181:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,182:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,183:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,187:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,190:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,193:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,193:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,195:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,197:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,198:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,200:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,201:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,202:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,205:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,207:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,208:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,211:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,214:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,216:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,227:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,229:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,234:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,237:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,239:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,242:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,253:INFO:Calculating mean and std
2025-11-16 05:40:39,253:INFO:Creating metrics dataframe
2025-11-16 05:40:39,256:INFO:Uploading results into container
2025-11-16 05:40:39,256:INFO:Uploading model into container now
2025-11-16 05:40:39,257:INFO:_master_model_container: 2
2025-11-16 05:40:39,257:INFO:_display_container: 2
2025-11-16 05:40:39,257:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 05:40:39,257:INFO:create_model() successfully completed......................................
2025-11-16 05:40:39,360:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:39,360:INFO:Creating metrics dataframe
2025-11-16 05:40:39,364:INFO:Initializing Decision Tree Classifier
2025-11-16 05:40:39,364:INFO:Total runtime is 0.12512491941452025 minutes
2025-11-16 05:40:39,364:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:39,365:INFO:Initializing create_model()
2025-11-16 05:40:39,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:39,365:INFO:Checking exceptions
2025-11-16 05:40:39,365:INFO:Importing libraries
2025-11-16 05:40:39,365:INFO:Copying training dataset
2025-11-16 05:40:39,369:INFO:Defining folds
2025-11-16 05:40:39,370:INFO:Declaring metric variables
2025-11-16 05:40:39,370:INFO:Importing untrained model
2025-11-16 05:40:39,370:INFO:Decision Tree Classifier Imported successfully
2025-11-16 05:40:39,370:INFO:Starting cross validation
2025-11-16 05:40:39,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:39,404:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,405:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,406:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,407:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,409:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,409:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,410:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,410:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,412:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,413:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,413:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,415:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,415:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,416:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,416:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,416:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,417:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,418:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,419:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,419:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,422:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,436:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,437:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,443:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,445:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,446:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,448:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,448:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,452:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,454:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,455:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,455:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,457:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,470:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,471:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,472:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:39,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,484:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,485:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,494:INFO:Calculating mean and std
2025-11-16 05:40:39,495:INFO:Creating metrics dataframe
2025-11-16 05:40:39,497:INFO:Uploading results into container
2025-11-16 05:40:39,497:INFO:Uploading model into container now
2025-11-16 05:40:39,498:INFO:_master_model_container: 3
2025-11-16 05:40:39,498:INFO:_display_container: 2
2025-11-16 05:40:39,498:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-16 05:40:39,498:INFO:create_model() successfully completed......................................
2025-11-16 05:40:39,603:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:39,603:INFO:Creating metrics dataframe
2025-11-16 05:40:39,606:INFO:Initializing SVM - Linear Kernel
2025-11-16 05:40:39,606:INFO:Total runtime is 0.1291627248128255 minutes
2025-11-16 05:40:39,607:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:39,607:INFO:Initializing create_model()
2025-11-16 05:40:39,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:39,607:INFO:Checking exceptions
2025-11-16 05:40:39,607:INFO:Importing libraries
2025-11-16 05:40:39,607:INFO:Copying training dataset
2025-11-16 05:40:39,612:INFO:Defining folds
2025-11-16 05:40:39,612:INFO:Declaring metric variables
2025-11-16 05:40:39,612:INFO:Importing untrained model
2025-11-16 05:40:39,613:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:40:39,613:INFO:Starting cross validation
2025-11-16 05:40:39,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:39,684:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:40:39,685:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:40:39,686:INFO:Initializing create_model()
2025-11-16 05:40:39,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:39,686:INFO:Checking exceptions
2025-11-16 05:40:39,686:INFO:Importing libraries
2025-11-16 05:40:39,686:INFO:Copying training dataset
2025-11-16 05:40:39,691:INFO:Defining folds
2025-11-16 05:40:39,691:INFO:Declaring metric variables
2025-11-16 05:40:39,692:INFO:Importing untrained model
2025-11-16 05:40:39,692:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:40:39,692:INFO:Starting cross validation
2025-11-16 05:40:39,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:39,752:ERROR:create_model() for svm raised an exception or returned all 0.0:
2025-11-16 05:40:39,755:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:40:39,755:INFO:Initializing Ridge Classifier
2025-11-16 05:40:39,755:INFO:Total runtime is 0.1316393971443176 minutes
2025-11-16 05:40:39,755:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:39,756:INFO:Initializing create_model()
2025-11-16 05:40:39,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:39,756:INFO:Checking exceptions
2025-11-16 05:40:39,756:INFO:Importing libraries
2025-11-16 05:40:39,756:INFO:Copying training dataset
2025-11-16 05:40:39,761:INFO:Defining folds
2025-11-16 05:40:39,762:INFO:Declaring metric variables
2025-11-16 05:40:39,762:INFO:Importing untrained model
2025-11-16 05:40:39,762:INFO:Ridge Classifier Imported successfully
2025-11-16 05:40:39,762:INFO:Starting cross validation
2025-11-16 05:40:39,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:39,803:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,803:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,805:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,805:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,807:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,809:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,809:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,811:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,812:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,812:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,813:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,813:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,815:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,815:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,816:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,816:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,817:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,817:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,819:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,819:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,820:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,820:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,820:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,821:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,822:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,823:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,823:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,825:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,841:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,843:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,844:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,845:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,846:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,846:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,846:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,848:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,848:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,848:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,849:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,851:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,851:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,852:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,852:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,852:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,854:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,854:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,854:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,856:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,856:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,857:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,857:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,857:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,857:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,859:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,860:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,876:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,878:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,881:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,883:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:39,883:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,886:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,886:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,888:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,888:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,891:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:39,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:39,896:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:39,901:INFO:Calculating mean and std
2025-11-16 05:40:39,901:INFO:Creating metrics dataframe
2025-11-16 05:40:39,903:INFO:Uploading results into container
2025-11-16 05:40:39,904:INFO:Uploading model into container now
2025-11-16 05:40:39,904:INFO:_master_model_container: 4
2025-11-16 05:40:39,904:INFO:_display_container: 2
2025-11-16 05:40:39,905:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-16 05:40:39,905:INFO:create_model() successfully completed......................................
2025-11-16 05:40:40,008:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:40,009:INFO:Creating metrics dataframe
2025-11-16 05:40:40,012:INFO:Initializing Random Forest Classifier
2025-11-16 05:40:40,012:INFO:Total runtime is 0.13592820167541503 minutes
2025-11-16 05:40:40,013:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:40,013:INFO:Initializing create_model()
2025-11-16 05:40:40,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:40,013:INFO:Checking exceptions
2025-11-16 05:40:40,013:INFO:Importing libraries
2025-11-16 05:40:40,013:INFO:Copying training dataset
2025-11-16 05:40:40,018:INFO:Defining folds
2025-11-16 05:40:40,018:INFO:Declaring metric variables
2025-11-16 05:40:40,018:INFO:Importing untrained model
2025-11-16 05:40:40,018:INFO:Random Forest Classifier Imported successfully
2025-11-16 05:40:40,019:INFO:Starting cross validation
2025-11-16 05:40:40,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:40,284:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,286:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,290:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,291:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,293:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,293:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,295:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,298:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,298:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,299:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,301:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,302:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,302:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,305:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,305:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,306:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,308:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,308:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,308:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,310:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,313:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,316:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,319:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,319:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,321:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,533:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,536:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,539:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,542:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,545:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,546:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,547:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,548:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,551:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,554:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,557:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,557:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,559:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,569:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,571:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,574:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,577:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,580:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,580:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,582:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,586:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,589:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,592:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,595:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,595:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,597:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,871:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,873:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,873:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:40,875:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,876:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,882:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:40,882:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,883:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:40,887:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:40,893:INFO:Calculating mean and std
2025-11-16 05:40:40,894:INFO:Creating metrics dataframe
2025-11-16 05:40:40,896:INFO:Uploading results into container
2025-11-16 05:40:40,897:INFO:Uploading model into container now
2025-11-16 05:40:40,897:INFO:_master_model_container: 5
2025-11-16 05:40:40,897:INFO:_display_container: 2
2025-11-16 05:40:40,898:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-16 05:40:40,898:INFO:create_model() successfully completed......................................
2025-11-16 05:40:41,002:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:41,002:INFO:Creating metrics dataframe
2025-11-16 05:40:41,006:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 05:40:41,006:INFO:Total runtime is 0.15248878399531046 minutes
2025-11-16 05:40:41,006:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:41,007:INFO:Initializing create_model()
2025-11-16 05:40:41,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,007:INFO:Checking exceptions
2025-11-16 05:40:41,007:INFO:Importing libraries
2025-11-16 05:40:41,007:INFO:Copying training dataset
2025-11-16 05:40:41,012:INFO:Defining folds
2025-11-16 05:40:41,012:INFO:Declaring metric variables
2025-11-16 05:40:41,013:INFO:Importing untrained model
2025-11-16 05:40:41,013:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:40:41,013:INFO:Starting cross validation
2025-11-16 05:40:41,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,073:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:40:41,075:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:40:41,075:INFO:Initializing create_model()
2025-11-16 05:40:41,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,075:INFO:Checking exceptions
2025-11-16 05:40:41,075:INFO:Importing libraries
2025-11-16 05:40:41,075:INFO:Copying training dataset
2025-11-16 05:40:41,080:INFO:Defining folds
2025-11-16 05:40:41,081:INFO:Declaring metric variables
2025-11-16 05:40:41,081:INFO:Importing untrained model
2025-11-16 05:40:41,081:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:40:41,081:INFO:Starting cross validation
2025-11-16 05:40:41,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,137:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-11-16 05:40:41,140:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:40:41,140:INFO:Initializing Ada Boost Classifier
2025-11-16 05:40:41,141:INFO:Total runtime is 0.15473141272862753 minutes
2025-11-16 05:40:41,141:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:41,141:INFO:Initializing create_model()
2025-11-16 05:40:41,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,141:INFO:Checking exceptions
2025-11-16 05:40:41,141:INFO:Importing libraries
2025-11-16 05:40:41,141:INFO:Copying training dataset
2025-11-16 05:40:41,146:INFO:Defining folds
2025-11-16 05:40:41,147:INFO:Declaring metric variables
2025-11-16 05:40:41,147:INFO:Importing untrained model
2025-11-16 05:40:41,147:INFO:Ada Boost Classifier Imported successfully
2025-11-16 05:40:41,147:INFO:Starting cross validation
2025-11-16 05:40:41,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,173:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,175:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,186:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,187:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,188:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,188:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,189:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,190:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,191:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,193:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,194:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,196:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,197:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,197:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,201:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,201:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,205:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,208:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,211:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,213:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,214:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,217:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,223:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,224:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,226:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,226:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,227:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,228:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,229:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,229:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,234:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,235:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,235:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,237:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,241:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,242:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,244:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,244:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,245:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,247:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,247:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,249:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:40:41,250:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,250:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,250:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,250:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,252:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,252:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,257:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,259:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,261:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,262:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,263:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,265:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,266:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,267:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,268:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,272:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,272:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,285:INFO:Calculating mean and std
2025-11-16 05:40:41,285:INFO:Creating metrics dataframe
2025-11-16 05:40:41,287:INFO:Uploading results into container
2025-11-16 05:40:41,288:INFO:Uploading model into container now
2025-11-16 05:40:41,288:INFO:_master_model_container: 6
2025-11-16 05:40:41,288:INFO:_display_container: 2
2025-11-16 05:40:41,289:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 05:40:41,289:INFO:create_model() successfully completed......................................
2025-11-16 05:40:41,390:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:41,390:INFO:Creating metrics dataframe
2025-11-16 05:40:41,394:INFO:Initializing Gradient Boosting Classifier
2025-11-16 05:40:41,394:INFO:Total runtime is 0.15895209312438965 minutes
2025-11-16 05:40:41,394:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:41,394:INFO:Initializing create_model()
2025-11-16 05:40:41,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,394:INFO:Checking exceptions
2025-11-16 05:40:41,394:INFO:Importing libraries
2025-11-16 05:40:41,394:INFO:Copying training dataset
2025-11-16 05:40:41,399:INFO:Defining folds
2025-11-16 05:40:41,399:INFO:Declaring metric variables
2025-11-16 05:40:41,399:INFO:Importing untrained model
2025-11-16 05:40:41,400:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:40:41,400:INFO:Starting cross validation
2025-11-16 05:40:41,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,462:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:40:41,464:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:40:41,464:INFO:Initializing create_model()
2025-11-16 05:40:41,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,464:INFO:Checking exceptions
2025-11-16 05:40:41,464:INFO:Importing libraries
2025-11-16 05:40:41,465:INFO:Copying training dataset
2025-11-16 05:40:41,470:INFO:Defining folds
2025-11-16 05:40:41,470:INFO:Declaring metric variables
2025-11-16 05:40:41,470:INFO:Importing untrained model
2025-11-16 05:40:41,471:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:40:41,471:INFO:Starting cross validation
2025-11-16 05:40:41,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,525:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2025-11-16 05:40:41,528:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:40:41,528:INFO:Initializing Linear Discriminant Analysis
2025-11-16 05:40:41,529:INFO:Total runtime is 0.1611968755722046 minutes
2025-11-16 05:40:41,529:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:41,529:INFO:Initializing create_model()
2025-11-16 05:40:41,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,529:INFO:Checking exceptions
2025-11-16 05:40:41,529:INFO:Importing libraries
2025-11-16 05:40:41,529:INFO:Copying training dataset
2025-11-16 05:40:41,534:INFO:Defining folds
2025-11-16 05:40:41,534:INFO:Declaring metric variables
2025-11-16 05:40:41,534:INFO:Importing untrained model
2025-11-16 05:40:41,535:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 05:40:41,535:INFO:Starting cross validation
2025-11-16 05:40:41,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,571:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,572:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,572:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,573:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,574:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,575:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,575:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,577:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,578:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,578:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,580:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,581:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,583:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,583:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,583:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,583:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,585:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,586:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,586:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,589:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,591:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,592:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,594:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,607:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,607:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,608:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,611:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,611:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,612:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,614:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,614:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,615:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,615:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,616:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,617:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,617:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,618:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,618:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,618:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,619:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,619:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,620:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,620:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,620:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,622:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,622:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,625:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,625:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,627:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,641:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,641:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:41,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,643:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,645:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,646:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,649:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,649:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:41,651:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,652:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,652:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,652:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:41,654:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,655:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:41,659:INFO:Calculating mean and std
2025-11-16 05:40:41,660:INFO:Creating metrics dataframe
2025-11-16 05:40:41,662:INFO:Uploading results into container
2025-11-16 05:40:41,663:INFO:Uploading model into container now
2025-11-16 05:40:41,663:INFO:_master_model_container: 7
2025-11-16 05:40:41,663:INFO:_display_container: 2
2025-11-16 05:40:41,664:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 05:40:41,664:INFO:create_model() successfully completed......................................
2025-11-16 05:40:41,767:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:41,767:INFO:Creating metrics dataframe
2025-11-16 05:40:41,771:INFO:Initializing Extra Trees Classifier
2025-11-16 05:40:41,771:INFO:Total runtime is 0.1652359127998352 minutes
2025-11-16 05:40:41,771:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:41,771:INFO:Initializing create_model()
2025-11-16 05:40:41,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:41,771:INFO:Checking exceptions
2025-11-16 05:40:41,772:INFO:Importing libraries
2025-11-16 05:40:41,772:INFO:Copying training dataset
2025-11-16 05:40:41,776:INFO:Defining folds
2025-11-16 05:40:41,776:INFO:Declaring metric variables
2025-11-16 05:40:41,776:INFO:Importing untrained model
2025-11-16 05:40:41,777:INFO:Extra Trees Classifier Imported successfully
2025-11-16 05:40:41,777:INFO:Starting cross validation
2025-11-16 05:40:41,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:41,995:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:41,998:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,001:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,002:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,003:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,005:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,006:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,007:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,007:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,008:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,008:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,010:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,010:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,013:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,013:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,013:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,015:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,016:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,016:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,018:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,019:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,019:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,021:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,023:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,027:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,030:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,030:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,032:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,228:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,228:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,229:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,233:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,233:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,234:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,234:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,235:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,237:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,237:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,238:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,240:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,241:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,242:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,242:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,244:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,244:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,246:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:42,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,489:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,489:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,493:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,493:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,493:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,495:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,496:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,501:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,512:INFO:Calculating mean and std
2025-11-16 05:40:42,512:INFO:Creating metrics dataframe
2025-11-16 05:40:42,515:INFO:Uploading results into container
2025-11-16 05:40:42,515:INFO:Uploading model into container now
2025-11-16 05:40:42,516:INFO:_master_model_container: 8
2025-11-16 05:40:42,516:INFO:_display_container: 2
2025-11-16 05:40:42,516:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-16 05:40:42,516:INFO:create_model() successfully completed......................................
2025-11-16 05:40:42,620:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:42,620:INFO:Creating metrics dataframe
2025-11-16 05:40:42,623:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 05:40:42,623:INFO:Total runtime is 0.17944565216700237 minutes
2025-11-16 05:40:42,624:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:42,624:INFO:Initializing create_model()
2025-11-16 05:40:42,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:42,624:INFO:Checking exceptions
2025-11-16 05:40:42,624:INFO:Importing libraries
2025-11-16 05:40:42,624:INFO:Copying training dataset
2025-11-16 05:40:42,629:INFO:Defining folds
2025-11-16 05:40:42,629:INFO:Declaring metric variables
2025-11-16 05:40:42,629:INFO:Importing untrained model
2025-11-16 05:40:42,630:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 05:40:42,630:INFO:Starting cross validation
2025-11-16 05:40:42,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:42,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:42,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,875:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,877:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:42,880:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,884:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,887:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,888:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,891:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,891:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,892:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:42,893:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,901:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,904:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,904:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,905:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,906:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,908:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:42,909:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,958:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:42,960:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,970:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,982:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:42,994:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:42,995:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,006:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,094:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,102:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,106:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,104:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,118:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,119:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,120:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,122:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,123:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,123:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,123:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,124:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,125:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,132:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,132:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,136:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,143:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,143:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,153:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,198:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,213:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,214:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,250:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,254:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,257:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,263:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,263:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,265:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:40:43,273:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,276:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,281:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,282:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,283:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,293:INFO:Calculating mean and std
2025-11-16 05:40:43,294:INFO:Creating metrics dataframe
2025-11-16 05:40:43,296:INFO:Uploading results into container
2025-11-16 05:40:43,296:INFO:Uploading model into container now
2025-11-16 05:40:43,297:INFO:_master_model_container: 9
2025-11-16 05:40:43,297:INFO:_display_container: 2
2025-11-16 05:40:43,298:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 05:40:43,298:INFO:create_model() successfully completed......................................
2025-11-16 05:40:43,397:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:43,397:INFO:Creating metrics dataframe
2025-11-16 05:40:43,401:INFO:Initializing Dummy Classifier
2025-11-16 05:40:43,401:INFO:Total runtime is 0.1924072782198588 minutes
2025-11-16 05:40:43,401:INFO:SubProcess create_model() called ==================================
2025-11-16 05:40:43,402:INFO:Initializing create_model()
2025-11-16 05:40:43,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f26dbdb2310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:43,402:INFO:Checking exceptions
2025-11-16 05:40:43,402:INFO:Importing libraries
2025-11-16 05:40:43,402:INFO:Copying training dataset
2025-11-16 05:40:43,406:INFO:Defining folds
2025-11-16 05:40:43,406:INFO:Declaring metric variables
2025-11-16 05:40:43,407:INFO:Importing untrained model
2025-11-16 05:40:43,407:INFO:Dummy Classifier Imported successfully
2025-11-16 05:40:43,407:INFO:Starting cross validation
2025-11-16 05:40:43,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:40:43,437:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,439:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,439:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,440:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,443:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,445:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,446:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,455:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,456:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,458:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,466:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,467:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,467:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,470:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,473:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,473:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,477:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,484:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,485:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,488:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,494:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,496:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,498:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:40:43,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,502:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,502:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:40:43,507:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:40:43,510:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:40:43,516:INFO:Calculating mean and std
2025-11-16 05:40:43,517:INFO:Creating metrics dataframe
2025-11-16 05:40:43,519:INFO:Uploading results into container
2025-11-16 05:40:43,519:INFO:Uploading model into container now
2025-11-16 05:40:43,520:INFO:_master_model_container: 10
2025-11-16 05:40:43,520:INFO:_display_container: 2
2025-11-16 05:40:43,520:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-16 05:40:43,520:INFO:create_model() successfully completed......................................
2025-11-16 05:40:43,625:INFO:SubProcess create_model() end ==================================
2025-11-16 05:40:43,625:INFO:Creating metrics dataframe
2025-11-16 05:40:43,629:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-16 05:40:43,631:INFO:Initializing create_model()
2025-11-16 05:40:43,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f26f3067ed0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:40:43,631:INFO:Checking exceptions
2025-11-16 05:40:43,632:INFO:Importing libraries
2025-11-16 05:40:43,633:INFO:Copying training dataset
2025-11-16 05:40:43,637:INFO:Defining folds
2025-11-16 05:40:43,637:INFO:Declaring metric variables
2025-11-16 05:40:43,637:INFO:Importing untrained model
2025-11-16 05:40:43,638:INFO:Declaring custom model
2025-11-16 05:40:43,638:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:40:43,639:INFO:Cross validation set to False
2025-11-16 05:40:43,639:INFO:Fitting Model
2025-11-16 05:40:43,651:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:40:43,651:INFO:create_model() successfully completed......................................
2025-11-16 05:40:43,759:INFO:_master_model_container: 10
2025-11-16 05:40:43,759:INFO:_display_container: 2
2025-11-16 05:40:43,760:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:40:43,760:INFO:compare_models() successfully completed......................................
2025-11-16 05:46:42,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:46:42,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:46:42,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:46:42,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-16 05:46:42,968:INFO:PyCaret ClassificationExperiment
2025-11-16 05:46:42,968:INFO:Logging name: clf-default-name
2025-11-16 05:46:42,968:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-16 05:46:42,968:INFO:version 3.3.2
2025-11-16 05:46:42,968:INFO:Initializing setup()
2025-11-16 05:46:42,968:INFO:self.USI: 0a63
2025-11-16 05:46:42,968:INFO:self._variable_keys: {'X', 'data', '_ml_usecase', 'exp_name_log', 'memory', 'logging_param', 'gpu_param', 'fold_generator', 'exp_id', 'fold_groups_param', 'fix_imbalance', 'y_train', 'target_param', 'seed', 'X_train', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'USI', 'is_multiclass', 'n_jobs_param', 'pipeline', 'X_test', 'idx', 'html_param', '_available_plots'}
2025-11-16 05:46:42,968:INFO:Checking environment
2025-11-16 05:46:42,968:INFO:python_version: 3.11.14
2025-11-16 05:46:42,968:INFO:python_build: ('main', 'Nov 16 2025 04:28:49')
2025-11-16 05:46:42,969:INFO:machine: x86_64
2025-11-16 05:46:42,971:INFO:platform: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:46:42,972:INFO:Memory: svmem(total=8345706496, available=7460196352, percent=10.6, used=885510144, free=1202634752, active=1127092224, inactive=5479534592, buffers=128557056, cached=6441566208, shared=647168, slab=450809856)
2025-11-16 05:46:42,972:INFO:Physical Core: 4
2025-11-16 05:46:42,973:INFO:Logical Core: 4
2025-11-16 05:46:42,973:INFO:Checking libraries
2025-11-16 05:46:42,973:INFO:System:
2025-11-16 05:46:42,973:INFO:    python: 3.11.14 (main, Nov 16 2025, 04:28:49) [GCC 13.3.0]
2025-11-16 05:46:42,973:INFO:executable: /home/jules/.pyenv/versions/3.11.14/bin/python
2025-11-16 05:46:42,973:INFO:   machine: Linux-6.8.0-x86_64-with-glibc2.39
2025-11-16 05:46:42,973:INFO:PyCaret required dependencies:
2025-11-16 05:46:43,003:INFO:                 pip: 24.0
2025-11-16 05:46:43,004:INFO:          setuptools: 79.0.1
2025-11-16 05:46:43,004:INFO:             pycaret: 3.3.2
2025-11-16 05:46:43,004:INFO:             IPython: 9.7.0
2025-11-16 05:46:43,004:INFO:          ipywidgets: 8.1.8
2025-11-16 05:46:43,004:INFO:                tqdm: 4.67.1
2025-11-16 05:46:43,004:INFO:               numpy: 1.26.4
2025-11-16 05:46:43,004:INFO:              pandas: 2.1.4
2025-11-16 05:46:43,004:INFO:              jinja2: 3.1.6
2025-11-16 05:46:43,004:INFO:               scipy: 1.11.4
2025-11-16 05:46:43,004:INFO:              joblib: 1.3.2
2025-11-16 05:46:43,004:INFO:             sklearn: 1.4.2
2025-11-16 05:46:43,004:INFO:                pyod: 2.0.5
2025-11-16 05:46:43,004:INFO:            imblearn: 0.14.0
2025-11-16 05:46:43,004:INFO:   category_encoders: 2.7.0
2025-11-16 05:46:43,004:INFO:            lightgbm: 4.6.0
2025-11-16 05:46:43,004:INFO:               numba: 0.62.1
2025-11-16 05:46:43,004:INFO:            requests: 2.32.5
2025-11-16 05:46:43,004:INFO:          matplotlib: 3.7.5
2025-11-16 05:46:43,004:INFO:          scikitplot: 0.3.7
2025-11-16 05:46:43,004:INFO:         yellowbrick: 1.5
2025-11-16 05:46:43,004:INFO:              plotly: 6.4.0
2025-11-16 05:46:43,004:INFO:    plotly-resampler: Not installed
2025-11-16 05:46:43,004:INFO:             kaleido: 1.2.0
2025-11-16 05:46:43,004:INFO:           schemdraw: 0.15
2025-11-16 05:46:43,004:INFO:         statsmodels: 0.14.5
2025-11-16 05:46:43,005:INFO:              sktime: 0.26.0
2025-11-16 05:46:43,005:INFO:               tbats: 1.1.3
2025-11-16 05:46:43,005:INFO:            pmdarima: 2.0.4
2025-11-16 05:46:43,005:INFO:              psutil: 7.1.3
2025-11-16 05:46:43,005:INFO:          markupsafe: 3.0.3
2025-11-16 05:46:43,005:INFO:             pickle5: Not installed
2025-11-16 05:46:43,005:INFO:         cloudpickle: 3.1.2
2025-11-16 05:46:43,005:INFO:         deprecation: 2.1.0
2025-11-16 05:46:43,005:INFO:              xxhash: 3.6.0
2025-11-16 05:46:43,005:INFO:           wurlitzer: 3.1.1
2025-11-16 05:46:43,005:INFO:PyCaret optional dependencies:
2025-11-16 05:46:43,041:INFO:                shap: 0.49.1
2025-11-16 05:46:43,041:INFO:           interpret: Not installed
2025-11-16 05:46:43,041:INFO:                umap: Not installed
2025-11-16 05:46:43,041:INFO:     ydata_profiling: Not installed
2025-11-16 05:46:43,041:INFO:  explainerdashboard: Not installed
2025-11-16 05:46:43,041:INFO:             autoviz: Not installed
2025-11-16 05:46:43,041:INFO:           fairlearn: Not installed
2025-11-16 05:46:43,041:INFO:          deepchecks: Not installed
2025-11-16 05:46:43,041:INFO:             xgboost: Not installed
2025-11-16 05:46:43,041:INFO:            catboost: Not installed
2025-11-16 05:46:43,041:INFO:              kmodes: Not installed
2025-11-16 05:46:43,041:INFO:             mlxtend: Not installed
2025-11-16 05:46:43,042:INFO:       statsforecast: Not installed
2025-11-16 05:46:43,042:INFO:        tune_sklearn: Not installed
2025-11-16 05:46:43,042:INFO:                 ray: Not installed
2025-11-16 05:46:43,042:INFO:            hyperopt: Not installed
2025-11-16 05:46:43,042:INFO:              optuna: Not installed
2025-11-16 05:46:43,042:INFO:               skopt: Not installed
2025-11-16 05:46:43,042:INFO:              mlflow: Not installed
2025-11-16 05:46:43,042:INFO:              gradio: Not installed
2025-11-16 05:46:43,042:INFO:             fastapi: Not installed
2025-11-16 05:46:43,042:INFO:             uvicorn: Not installed
2025-11-16 05:46:43,042:INFO:              m2cgen: Not installed
2025-11-16 05:46:43,042:INFO:           evidently: Not installed
2025-11-16 05:46:43,042:INFO:               fugue: Not installed
2025-11-16 05:46:43,042:INFO:           streamlit: Not installed
2025-11-16 05:46:43,042:INFO:             prophet: Not installed
2025-11-16 05:46:43,042:INFO:None
2025-11-16 05:46:43,042:INFO:Set up data.
2025-11-16 05:46:43,048:INFO:Set up folding strategy.
2025-11-16 05:46:43,048:INFO:Set up train/test split.
2025-11-16 05:46:43,054:INFO:Set up index.
2025-11-16 05:46:43,054:INFO:Assigning column types.
2025-11-16 05:46:43,059:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-16 05:46:43,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,244:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,286:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-16 05:46:43,353:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,460:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-16 05:46:43,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,501:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-16 05:46:43,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,608:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,718:INFO:Preparing preprocessing pipeline...
2025-11-16 05:46:43,719:INFO:Set up label encoding.
2025-11-16 05:46:43,719:INFO:Set up simple imputation.
2025-11-16 05:46:43,779:INFO:Finished creating preprocessing pipeline.
2025-11-16 05:46:43,785:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '5', '6',
                                             '7', '8', '9', '10', '11', '12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-16 05:46:43,785:INFO:Creating final display dataframe.
2025-11-16 05:46:43,886:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                13
2                   Target type        Multiclass
3                Target mapping           24.0: 0
4           Original data shape         (100, 14)
5        Transformed data shape         (100, 14)
6   Transformed train set shape          (70, 14)
7    Transformed test set shape          (30, 14)
8              Numeric features                13
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              0a63
2025-11-16 05:46:43,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:43,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:44,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:44,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-16 05:46:44,097:INFO:setup() successfully completed in 1.13s...............
2025-11-16 05:46:44,098:INFO:Initializing compare_models()
2025-11-16 05:46:44,098:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-16 05:46:44,098:INFO:Checking exceptions
2025-11-16 05:46:44,103:INFO:Preparing display monitor
2025-11-16 05:46:44,108:INFO:Initializing Logistic Regression
2025-11-16 05:46:44,108:INFO:Total runtime is 1.5457471211751302e-06 minutes
2025-11-16 05:46:44,108:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:44,109:INFO:Initializing create_model()
2025-11-16 05:46:44,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:44,109:INFO:Checking exceptions
2025-11-16 05:46:44,109:INFO:Importing libraries
2025-11-16 05:46:44,109:INFO:Copying training dataset
2025-11-16 05:46:44,114:INFO:Defining folds
2025-11-16 05:46:44,114:INFO:Declaring metric variables
2025-11-16 05:46:44,114:INFO:Importing untrained model
2025-11-16 05:46:44,115:INFO:Logistic Regression Imported successfully
2025-11-16 05:46:44,115:INFO:Starting cross validation
2025-11-16 05:46:44,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:46,701:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:46:46,711:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:46:46,712:INFO:Initializing create_model()
2025-11-16 05:46:46,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:46,712:INFO:Checking exceptions
2025-11-16 05:46:46,712:INFO:Importing libraries
2025-11-16 05:46:46,712:INFO:Copying training dataset
2025-11-16 05:46:46,719:INFO:Defining folds
2025-11-16 05:46:46,720:INFO:Declaring metric variables
2025-11-16 05:46:46,720:INFO:Importing untrained model
2025-11-16 05:46:46,721:INFO:Logistic Regression Imported successfully
2025-11-16 05:46:46,721:INFO:Starting cross validation
2025-11-16 05:46:46,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:46,793:ERROR:create_model() for lr raised an exception or returned all 0.0:
2025-11-16 05:46:46,796:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py", line 1246, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2025-11-16 05:46:46,796:INFO:Initializing K Neighbors Classifier
2025-11-16 05:46:46,797:INFO:Total runtime is 0.04480570952097575 minutes
2025-11-16 05:46:46,797:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:46,797:INFO:Initializing create_model()
2025-11-16 05:46:46,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:46,797:INFO:Checking exceptions
2025-11-16 05:46:46,797:INFO:Importing libraries
2025-11-16 05:46:46,797:INFO:Copying training dataset
2025-11-16 05:46:46,802:INFO:Defining folds
2025-11-16 05:46:46,802:INFO:Declaring metric variables
2025-11-16 05:46:46,803:INFO:Importing untrained model
2025-11-16 05:46:46,803:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:46:46,803:INFO:Starting cross validation
2025-11-16 05:46:46,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:46,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,882:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,885:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,890:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,891:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,892:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,892:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,895:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,896:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,896:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,898:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,899:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,899:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,901:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,902:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,904:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,905:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,905:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,905:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,906:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,907:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,908:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,909:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,947:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,949:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,953:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,956:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,959:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,959:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,960:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,961:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,961:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,963:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,964:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,964:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:46,966:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,967:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,968:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,970:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,970:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,971:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,973:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:46,973:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,973:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,974:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,974:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,975:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,976:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,976:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:46,976:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:46,978:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,014:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,016:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,019:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,022:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,025:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,025:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,028:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,029:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,031:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,034:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,037:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,040:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,040:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,042:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,051:INFO:Calculating mean and std
2025-11-16 05:46:47,052:INFO:Creating metrics dataframe
2025-11-16 05:46:47,055:INFO:Uploading results into container
2025-11-16 05:46:47,055:INFO:Uploading model into container now
2025-11-16 05:46:47,056:INFO:_master_model_container: 1
2025-11-16 05:46:47,056:INFO:_display_container: 2
2025-11-16 05:46:47,057:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:46:47,057:INFO:create_model() successfully completed......................................
2025-11-16 05:46:47,250:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:47,251:INFO:Creating metrics dataframe
2025-11-16 05:46:47,259:INFO:Initializing Naive Bayes
2025-11-16 05:46:47,259:INFO:Total runtime is 0.05251467227935791 minutes
2025-11-16 05:46:47,260:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:47,260:INFO:Initializing create_model()
2025-11-16 05:46:47,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:47,261:INFO:Checking exceptions
2025-11-16 05:46:47,261:INFO:Importing libraries
2025-11-16 05:46:47,261:INFO:Copying training dataset
2025-11-16 05:46:47,274:INFO:Defining folds
2025-11-16 05:46:47,275:INFO:Declaring metric variables
2025-11-16 05:46:47,275:INFO:Importing untrained model
2025-11-16 05:46:47,276:INFO:Naive Bayes Imported successfully
2025-11-16 05:46:47,276:INFO:Starting cross validation
2025-11-16 05:46:47,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:47,363:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,367:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,367:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,371:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,371:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,374:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,374:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,379:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,381:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,382:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,385:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,387:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,387:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,388:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,388:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,390:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,390:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,391:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,391:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,394:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,394:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,395:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,398:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,398:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,404:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,418:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,418:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,423:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,436:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,440:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,445:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,452:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,452:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,454:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,457:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,458:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,460:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,460:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,464:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,464:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,464:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,465:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,465:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,466:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,477:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,484:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,492:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,492:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,497:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,510:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,512:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,516:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,518:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,521:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,523:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,527:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,530:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,530:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,533:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,534:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,534:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,537:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,550:INFO:Calculating mean and std
2025-11-16 05:46:47,552:INFO:Creating metrics dataframe
2025-11-16 05:46:47,558:INFO:Uploading results into container
2025-11-16 05:46:47,559:INFO:Uploading model into container now
2025-11-16 05:46:47,560:INFO:_master_model_container: 2
2025-11-16 05:46:47,560:INFO:_display_container: 2
2025-11-16 05:46:47,561:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-16 05:46:47,561:INFO:create_model() successfully completed......................................
2025-11-16 05:46:47,724:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:47,725:INFO:Creating metrics dataframe
2025-11-16 05:46:47,733:INFO:Initializing Decision Tree Classifier
2025-11-16 05:46:47,733:INFO:Total runtime is 0.06041100025177002 minutes
2025-11-16 05:46:47,733:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:47,734:INFO:Initializing create_model()
2025-11-16 05:46:47,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:47,734:INFO:Checking exceptions
2025-11-16 05:46:47,734:INFO:Importing libraries
2025-11-16 05:46:47,734:INFO:Copying training dataset
2025-11-16 05:46:47,745:INFO:Defining folds
2025-11-16 05:46:47,746:INFO:Declaring metric variables
2025-11-16 05:46:47,746:INFO:Importing untrained model
2025-11-16 05:46:47,747:INFO:Decision Tree Classifier Imported successfully
2025-11-16 05:46:47,748:INFO:Starting cross validation
2025-11-16 05:46:47,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:47,834:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,838:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,838:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,842:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,842:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,845:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,847:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,848:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,852:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,855:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,855:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,856:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,859:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,861:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,861:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,863:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,864:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,866:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,870:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,879:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,919:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,922:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,923:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,926:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,931:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,934:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,938:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,942:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,942:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:47,943:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,944:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,944:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,945:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,945:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,949:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,949:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,949:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,953:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,954:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,955:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,962:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,966:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:47,970:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,970:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,975:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,976:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,977:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:47,984:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:47,999:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:48,004:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,007:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:48,011:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,011:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,020:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,020:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,028:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,029:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,029:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,034:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,036:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,037:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,042:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,047:INFO:Calculating mean and std
2025-11-16 05:46:48,050:INFO:Creating metrics dataframe
2025-11-16 05:46:48,055:INFO:Uploading results into container
2025-11-16 05:46:48,057:INFO:Uploading model into container now
2025-11-16 05:46:48,058:INFO:_master_model_container: 3
2025-11-16 05:46:48,058:INFO:_display_container: 2
2025-11-16 05:46:48,059:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-16 05:46:48,059:INFO:create_model() successfully completed......................................
2025-11-16 05:46:48,212:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:48,212:INFO:Creating metrics dataframe
2025-11-16 05:46:48,218:INFO:Initializing SVM - Linear Kernel
2025-11-16 05:46:48,218:INFO:Total runtime is 0.06850154002507527 minutes
2025-11-16 05:46:48,219:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:48,219:INFO:Initializing create_model()
2025-11-16 05:46:48,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:48,219:INFO:Checking exceptions
2025-11-16 05:46:48,219:INFO:Importing libraries
2025-11-16 05:46:48,219:INFO:Copying training dataset
2025-11-16 05:46:48,227:INFO:Defining folds
2025-11-16 05:46:48,227:INFO:Declaring metric variables
2025-11-16 05:46:48,227:INFO:Importing untrained model
2025-11-16 05:46:48,228:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:46:48,229:INFO:Starting cross validation
2025-11-16 05:46:48,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:48,363:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:46:48,366:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:46:48,366:INFO:Initializing create_model()
2025-11-16 05:46:48,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:48,367:INFO:Checking exceptions
2025-11-16 05:46:48,367:INFO:Importing libraries
2025-11-16 05:46:48,367:INFO:Copying training dataset
2025-11-16 05:46:48,379:INFO:Defining folds
2025-11-16 05:46:48,379:INFO:Declaring metric variables
2025-11-16 05:46:48,379:INFO:Importing untrained model
2025-11-16 05:46:48,380:INFO:SVM - Linear Kernel Imported successfully
2025-11-16 05:46:48,381:INFO:Starting cross validation
2025-11-16 05:46:48,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:48,491:ERROR:create_model() for svm raised an exception or returned all 0.0:
2025-11-16 05:46:48,496:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 917, in fit
    return self._fit(
           ^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 704, in _fit
    self._partial_fit(
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 658, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:46:48,497:INFO:Initializing Ridge Classifier
2025-11-16 05:46:48,497:INFO:Total runtime is 0.07314965327580769 minutes
2025-11-16 05:46:48,498:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:48,498:INFO:Initializing create_model()
2025-11-16 05:46:48,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:48,499:INFO:Checking exceptions
2025-11-16 05:46:48,499:INFO:Importing libraries
2025-11-16 05:46:48,499:INFO:Copying training dataset
2025-11-16 05:46:48,508:INFO:Defining folds
2025-11-16 05:46:48,508:INFO:Declaring metric variables
2025-11-16 05:46:48,508:INFO:Importing untrained model
2025-11-16 05:46:48,509:INFO:Ridge Classifier Imported successfully
2025-11-16 05:46:48,509:INFO:Starting cross validation
2025-11-16 05:46:48,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:48,587:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,589:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,590:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,592:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,593:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,596:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,597:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,600:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,603:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,604:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,607:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,609:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,610:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,612:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,612:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,613:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,614:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,615:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,616:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,616:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,620:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,621:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,635:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,642:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,647:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,664:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,665:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,666:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,667:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,669:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,670:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,675:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,675:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,677:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,681:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,683:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,684:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,688:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,688:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,689:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,690:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,692:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,693:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,693:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,694:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,695:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,698:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,699:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,706:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,713:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,719:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,720:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,722:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,738:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,740:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:48,741:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,744:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,748:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,751:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,756:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,759:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:48,762:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,763:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,766:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,767:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:48,767:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,772:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:48,785:INFO:Calculating mean and std
2025-11-16 05:46:48,786:INFO:Creating metrics dataframe
2025-11-16 05:46:48,791:INFO:Uploading results into container
2025-11-16 05:46:48,791:INFO:Uploading model into container now
2025-11-16 05:46:48,793:INFO:_master_model_container: 4
2025-11-16 05:46:48,793:INFO:_display_container: 2
2025-11-16 05:46:48,793:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-16 05:46:48,793:INFO:create_model() successfully completed......................................
2025-11-16 05:46:48,954:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:48,954:INFO:Creating metrics dataframe
2025-11-16 05:46:48,960:INFO:Initializing Random Forest Classifier
2025-11-16 05:46:48,960:INFO:Total runtime is 0.08086325327555338 minutes
2025-11-16 05:46:48,960:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:48,961:INFO:Initializing create_model()
2025-11-16 05:46:48,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:48,961:INFO:Checking exceptions
2025-11-16 05:46:48,961:INFO:Importing libraries
2025-11-16 05:46:48,961:INFO:Copying training dataset
2025-11-16 05:46:48,977:INFO:Defining folds
2025-11-16 05:46:48,977:INFO:Declaring metric variables
2025-11-16 05:46:48,977:INFO:Importing untrained model
2025-11-16 05:46:48,978:INFO:Random Forest Classifier Imported successfully
2025-11-16 05:46:48,979:INFO:Starting cross validation
2025-11-16 05:46:48,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:49,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,454:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,458:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,459:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,469:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,482:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,493:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,498:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,509:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,889:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,900:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,903:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,905:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,906:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,911:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,911:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,914:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,917:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,918:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,919:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,921:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,923:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,925:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:49,926:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,928:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,928:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,930:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,932:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,933:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,933:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,936:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,937:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,944:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:49,951:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:49,951:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:49,954:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:50,611:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:50,617:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,627:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,636:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,648:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:50,649:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:50,656:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:50,659:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:50,663:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,675:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,687:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:50,699:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:50,700:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:50,708:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:50,720:INFO:Calculating mean and std
2025-11-16 05:46:50,723:INFO:Creating metrics dataframe
2025-11-16 05:46:50,730:INFO:Uploading results into container
2025-11-16 05:46:50,732:INFO:Uploading model into container now
2025-11-16 05:46:50,734:INFO:_master_model_container: 5
2025-11-16 05:46:50,734:INFO:_display_container: 2
2025-11-16 05:46:50,735:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-16 05:46:50,735:INFO:create_model() successfully completed......................................
2025-11-16 05:46:50,956:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:50,956:INFO:Creating metrics dataframe
2025-11-16 05:46:50,968:INFO:Initializing Quadratic Discriminant Analysis
2025-11-16 05:46:50,968:INFO:Total runtime is 0.11433022419611613 minutes
2025-11-16 05:46:50,969:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:50,970:INFO:Initializing create_model()
2025-11-16 05:46:50,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:50,970:INFO:Checking exceptions
2025-11-16 05:46:50,970:INFO:Importing libraries
2025-11-16 05:46:50,970:INFO:Copying training dataset
2025-11-16 05:46:50,988:INFO:Defining folds
2025-11-16 05:46:50,989:INFO:Declaring metric variables
2025-11-16 05:46:50,990:INFO:Importing untrained model
2025-11-16 05:46:50,991:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:46:50,992:INFO:Starting cross validation
2025-11-16 05:46:50,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:51,149:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:46:51,152:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:46:51,153:INFO:Initializing create_model()
2025-11-16 05:46:51,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:51,153:INFO:Checking exceptions
2025-11-16 05:46:51,153:INFO:Importing libraries
2025-11-16 05:46:51,153:INFO:Copying training dataset
2025-11-16 05:46:51,170:INFO:Defining folds
2025-11-16 05:46:51,170:INFO:Declaring metric variables
2025-11-16 05:46:51,171:INFO:Importing untrained model
2025-11-16 05:46:51,172:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-16 05:46:51,173:INFO:Starting cross validation
2025-11-16 05:46:51,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:51,306:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-11-16 05:46:51,312:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-11-16 05:46:51,313:INFO:Initializing Ada Boost Classifier
2025-11-16 05:46:51,313:INFO:Total runtime is 0.12007433970769246 minutes
2025-11-16 05:46:51,313:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:51,314:INFO:Initializing create_model()
2025-11-16 05:46:51,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:51,314:INFO:Checking exceptions
2025-11-16 05:46:51,314:INFO:Importing libraries
2025-11-16 05:46:51,314:INFO:Copying training dataset
2025-11-16 05:46:51,324:INFO:Defining folds
2025-11-16 05:46:51,325:INFO:Declaring metric variables
2025-11-16 05:46:51,325:INFO:Importing untrained model
2025-11-16 05:46:51,326:INFO:Ada Boost Classifier Imported successfully
2025-11-16 05:46:51,326:INFO:Starting cross validation
2025-11-16 05:46:51,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:51,385:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,386:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,389:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,406:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,412:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,413:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,417:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,417:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,417:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,421:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,425:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,425:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,428:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,431:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,431:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,434:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,435:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,437:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,438:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,443:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,445:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,454:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,468:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,488:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,496:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,498:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,502:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,502:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,504:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,507:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,510:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,510:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,512:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,513:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,513:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,517:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,517:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,519:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,519:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,519:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,519:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,520:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,523:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,523:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,524:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,526:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,532:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,532:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,536:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,546:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,552:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-16 05:46:51,572:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,575:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,582:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,584:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:51,588:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,589:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,596:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,597:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,598:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,601:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,607:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:51,616:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,616:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:51,622:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:51,631:INFO:Calculating mean and std
2025-11-16 05:46:51,633:INFO:Creating metrics dataframe
2025-11-16 05:46:51,638:INFO:Uploading results into container
2025-11-16 05:46:51,639:INFO:Uploading model into container now
2025-11-16 05:46:51,640:INFO:_master_model_container: 6
2025-11-16 05:46:51,640:INFO:_display_container: 2
2025-11-16 05:46:51,641:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-16 05:46:51,641:INFO:create_model() successfully completed......................................
2025-11-16 05:46:51,813:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:51,813:INFO:Creating metrics dataframe
2025-11-16 05:46:51,823:INFO:Initializing Gradient Boosting Classifier
2025-11-16 05:46:51,824:INFO:Total runtime is 0.1285911202430725 minutes
2025-11-16 05:46:51,824:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:51,825:INFO:Initializing create_model()
2025-11-16 05:46:51,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:51,825:INFO:Checking exceptions
2025-11-16 05:46:51,825:INFO:Importing libraries
2025-11-16 05:46:51,826:INFO:Copying training dataset
2025-11-16 05:46:51,842:INFO:Defining folds
2025-11-16 05:46:51,842:INFO:Declaring metric variables
2025-11-16 05:46:51,843:INFO:Importing untrained model
2025-11-16 05:46:51,844:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:46:51,845:INFO:Starting cross validation
2025-11-16 05:46:51,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:51,977:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2025-11-16 05:46:51,979:WARNING:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:46:51,979:INFO:Initializing create_model()
2025-11-16 05:46:51,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:51,980:INFO:Checking exceptions
2025-11-16 05:46:51,980:INFO:Importing libraries
2025-11-16 05:46:51,980:INFO:Copying training dataset
2025-11-16 05:46:51,990:INFO:Defining folds
2025-11-16 05:46:51,990:INFO:Declaring metric variables
2025-11-16 05:46:51,990:INFO:Importing untrained model
2025-11-16 05:46:51,991:INFO:Gradient Boosting Classifier Imported successfully
2025-11-16 05:46:51,992:INFO:Starting cross validation
2025-11-16 05:46:51,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:52,104:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2025-11-16 05:46:52,108:ERROR:Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError:
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 665, in fit
    y = self._encode_y(y=y, sample_weight=None)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/ensemble/_gb.py", line 1520, in _encode_y
    raise ValueError(
ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.


2025-11-16 05:46:52,109:INFO:Initializing Linear Discriminant Analysis
2025-11-16 05:46:52,109:INFO:Total runtime is 0.13334129254023233 minutes
2025-11-16 05:46:52,109:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:52,110:INFO:Initializing create_model()
2025-11-16 05:46:52,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:52,110:INFO:Checking exceptions
2025-11-16 05:46:52,110:INFO:Importing libraries
2025-11-16 05:46:52,110:INFO:Copying training dataset
2025-11-16 05:46:52,121:INFO:Defining folds
2025-11-16 05:46:52,121:INFO:Declaring metric variables
2025-11-16 05:46:52,121:INFO:Importing untrained model
2025-11-16 05:46:52,122:INFO:Linear Discriminant Analysis Imported successfully
2025-11-16 05:46:52,122:INFO:Starting cross validation
2025-11-16 05:46:52,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:52,189:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,191:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,192:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,194:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,194:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,197:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,198:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,200:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,203:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,204:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,207:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,212:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,214:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,215:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,216:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,237:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,238:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,241:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,254:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,255:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,256:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,258:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,258:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,261:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,262:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,264:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,267:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,268:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,273:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,273:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,275:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,275:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,277:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,278:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,279:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,281:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,283:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,284:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,290:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,296:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,301:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,302:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,305:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,316:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,318:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:52,319:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,321:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,326:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,327:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,332:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,333:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,338:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,338:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,339:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,340:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,342:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,344:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,351:INFO:Calculating mean and std
2025-11-16 05:46:52,353:INFO:Creating metrics dataframe
2025-11-16 05:46:52,357:INFO:Uploading results into container
2025-11-16 05:46:52,358:INFO:Uploading model into container now
2025-11-16 05:46:52,358:INFO:_master_model_container: 7
2025-11-16 05:46:52,359:INFO:_display_container: 2
2025-11-16 05:46:52,359:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-16 05:46:52,359:INFO:create_model() successfully completed......................................
2025-11-16 05:46:52,518:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:52,518:INFO:Creating metrics dataframe
2025-11-16 05:46:52,525:INFO:Initializing Extra Trees Classifier
2025-11-16 05:46:52,525:INFO:Total runtime is 0.1402849038441976 minutes
2025-11-16 05:46:52,526:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:52,526:INFO:Initializing create_model()
2025-11-16 05:46:52,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:52,526:INFO:Checking exceptions
2025-11-16 05:46:52,527:INFO:Importing libraries
2025-11-16 05:46:52,527:INFO:Copying training dataset
2025-11-16 05:46:52,538:INFO:Defining folds
2025-11-16 05:46:52,539:INFO:Declaring metric variables
2025-11-16 05:46:52,539:INFO:Importing untrained model
2025-11-16 05:46:52,540:INFO:Extra Trees Classifier Imported successfully
2025-11-16 05:46:52,540:INFO:Starting cross validation
2025-11-16 05:46:52,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:52,949:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:52,955:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,963:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,963:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:52,968:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,971:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,977:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,978:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,978:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,980:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:52,982:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,984:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,985:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,991:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:52,992:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,992:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:52,997:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:52,998:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,000:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,003:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,004:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,004:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,008:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,012:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,019:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,021:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,022:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,023:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,197:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,202:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,205:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,205:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,207:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,208:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,208:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,208:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,210:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,213:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,214:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,216:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,217:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,217:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,219:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,220:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,221:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,222:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,225:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,229:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,231:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,232:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,234:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,461:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:53,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,465:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,467:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,468:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,470:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,471:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,473:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,473:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,474:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,475:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,487:INFO:Calculating mean and std
2025-11-16 05:46:53,488:INFO:Creating metrics dataframe
2025-11-16 05:46:53,490:INFO:Uploading results into container
2025-11-16 05:46:53,491:INFO:Uploading model into container now
2025-11-16 05:46:53,491:INFO:_master_model_container: 8
2025-11-16 05:46:53,491:INFO:_display_container: 2
2025-11-16 05:46:53,491:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-16 05:46:53,492:INFO:create_model() successfully completed......................................
2025-11-16 05:46:53,596:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:53,596:INFO:Creating metrics dataframe
2025-11-16 05:46:53,600:INFO:Initializing Light Gradient Boosting Machine
2025-11-16 05:46:53,600:INFO:Total runtime is 0.1581915020942688 minutes
2025-11-16 05:46:53,600:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:53,600:INFO:Initializing create_model()
2025-11-16 05:46:53,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:53,600:INFO:Checking exceptions
2025-11-16 05:46:53,600:INFO:Importing libraries
2025-11-16 05:46:53,600:INFO:Copying training dataset
2025-11-16 05:46:53,605:INFO:Defining folds
2025-11-16 05:46:53,605:INFO:Declaring metric variables
2025-11-16 05:46:53,606:INFO:Importing untrained model
2025-11-16 05:46:53,606:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-16 05:46:53,607:INFO:Starting cross validation
2025-11-16 05:46:53,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:53,842:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:53,852:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,858:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:53,859:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,865:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,866:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,870:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,872:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,873:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,874:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,875:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,876:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,877:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,894:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:53,912:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:53,912:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,914:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,915:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,921:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,925:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,925:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:53,928:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,929:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,930:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,934:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:53,935:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:53,936:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,078:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,092:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,095:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,106:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,107:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,113:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,114:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,114:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,116:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,118:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,122:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,125:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,125:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,127:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,162:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,176:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,179:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,182:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,184:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,191:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,195:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,199:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,202:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,206:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,209:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,211:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,258:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,260:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,263:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,266:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,269:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,270:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-11-16 05:46:54,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,271:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,274:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,277:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,280:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,280:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,282:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,288:INFO:Calculating mean and std
2025-11-16 05:46:54,289:INFO:Creating metrics dataframe
2025-11-16 05:46:54,291:INFO:Uploading results into container
2025-11-16 05:46:54,292:INFO:Uploading model into container now
2025-11-16 05:46:54,292:INFO:_master_model_container: 9
2025-11-16 05:46:54,292:INFO:_display_container: 2
2025-11-16 05:46:54,293:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-16 05:46:54,293:INFO:create_model() successfully completed......................................
2025-11-16 05:46:54,399:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:54,399:INFO:Creating metrics dataframe
2025-11-16 05:46:54,403:INFO:Initializing Dummy Classifier
2025-11-16 05:46:54,403:INFO:Total runtime is 0.17157926956812541 minutes
2025-11-16 05:46:54,403:INFO:SubProcess create_model() called ==================================
2025-11-16 05:46:54,403:INFO:Initializing create_model()
2025-11-16 05:46:54,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcfa8e0ddd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:54,404:INFO:Checking exceptions
2025-11-16 05:46:54,404:INFO:Importing libraries
2025-11-16 05:46:54,404:INFO:Copying training dataset
2025-11-16 05:46:54,408:INFO:Defining folds
2025-11-16 05:46:54,409:INFO:Declaring metric variables
2025-11-16 05:46:54,409:INFO:Importing untrained model
2025-11-16 05:46:54,409:INFO:Dummy Classifier Imported successfully
2025-11-16 05:46:54,409:INFO:Starting cross validation
2025-11-16 05:46:54,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-16 05:46:54,440:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,441:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,442:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,444:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,447:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,449:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,450:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,451:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,452:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,453:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,455:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,456:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,456:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,459:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,459:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,459:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,461:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,461:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,461:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,463:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,468:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,470:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,473:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,476:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,477:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,478:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,479:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,480:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,481:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,482:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,483:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,484:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,485:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,486:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,487:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,488:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,488:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,489:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,489:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,490:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,490:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,490:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,492:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,492:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,497:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,499:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,502:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,505:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,506:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/utils/_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes.

  warnings.warn(

2025-11-16 05:46:54,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,508:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,510:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,511:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,514:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 24.0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-11-16 05:46:54,516:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,516:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-11-16 05:46:54,518:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-11-16 05:46:54,520:INFO:Calculating mean and std
2025-11-16 05:46:54,521:INFO:Creating metrics dataframe
2025-11-16 05:46:54,523:INFO:Uploading results into container
2025-11-16 05:46:54,524:INFO:Uploading model into container now
2025-11-16 05:46:54,524:INFO:_master_model_container: 10
2025-11-16 05:46:54,524:INFO:_display_container: 2
2025-11-16 05:46:54,524:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-16 05:46:54,524:INFO:create_model() successfully completed......................................
2025-11-16 05:46:54,627:INFO:SubProcess create_model() end ==================================
2025-11-16 05:46:54,628:INFO:Creating metrics dataframe
2025-11-16 05:46:54,632:WARNING:/home/jules/.pyenv/versions/3.11.14/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-16 05:46:54,634:INFO:Initializing create_model()
2025-11-16 05:46:54,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-16 05:46:54,634:INFO:Checking exceptions
2025-11-16 05:46:54,635:INFO:Importing libraries
2025-11-16 05:46:54,635:INFO:Copying training dataset
2025-11-16 05:46:54,640:INFO:Defining folds
2025-11-16 05:46:54,640:INFO:Declaring metric variables
2025-11-16 05:46:54,641:INFO:Importing untrained model
2025-11-16 05:46:54,641:INFO:Declaring custom model
2025-11-16 05:46:54,641:INFO:K Neighbors Classifier Imported successfully
2025-11-16 05:46:54,642:INFO:Cross validation set to False
2025-11-16 05:46:54,642:INFO:Fitting Model
2025-11-16 05:46:54,655:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:46:54,655:INFO:create_model() successfully completed......................................
2025-11-16 05:46:54,773:INFO:_master_model_container: 10
2025-11-16 05:46:54,773:INFO:_display_container: 2
2025-11-16 05:46:54,773:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-16 05:46:54,773:INFO:compare_models() successfully completed......................................
2025-11-16 05:46:54,781:INFO:Initializing plot_model()
2025-11-16 05:46:54,781:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-16 05:46:54,781:INFO:Checking exceptions
2025-11-16 05:46:54,782:INFO:Initializing plot_model()
2025-11-16 05:46:54,782:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcfc00cffd0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), plot=summary, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-16 05:46:54,782:INFO:Checking exceptions
